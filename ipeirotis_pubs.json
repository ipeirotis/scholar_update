[{"bib": {"title": "Running experiments on Amazon Mechanical Turk", "year": 2010, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1626226", "author": "Gabriele Paolacci and Jesse Chandler and Panagiotis G Ipeirotis", "journal": "Judgment and Decision Making", "volume": "5", "number": "5", "pages": "411-419", "publisher": "Society for Judgment and Decision Making", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by participants recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting participants, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</div></div></div>", "eprint": "https://repub.eur.nl/pub/31983/jdm10630a.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:YsMSGLbcyi4C", "citedby": 3791, "_filled": true, "id_scholarcitedby": "2976868087255936079", "cites_per_year": {"2011": 72, "2012": 165, "2013": 303, "2014": 455, "2015": 558, "2016": 586, "2017": 630, "2018": 642, "2019": 329}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Duplicate record detection: A survey", "year": 2007, "url": "https://ieeexplore.ieee.org/abstract/document/4016511/", "author": "Ahmed K Elmagarmid and Panagiotis G Ipeirotis and Vassilios S Verykios", "journal": "IEEE Transactions on Knowledge and Data Engineering (TKDE)", "volume": "19", "number": "1", "pages": "1-16", "publisher": "IEEE Computer Society", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Often, in the real world, entities have two or more representations in databases. Duplicate records do not share a common key and/or they contain errors that make duplicate matching a difficult task. Errors are introduced as the result of transcription errors, incomplete information, lack of standard formats, or any combination of these factors. In this paper, we present a thorough analysis of the literature on duplicate record detection. We cover similarity metrics that are commonly used to detect similar field entries, and we present an extensive set of duplicate detection algorithms that can detect approximately duplicate records in a database. We also cover multiple techniques for improving the efficiency and scalability of approximate duplicate detection algorithms. We conclude with coverage of existing tools and with a brief discussion of the big open problems in the area</div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/27823/2/CeDER-PP-2007-15.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:u5HHmVD_uO8C", "citedby": 2033, "_filled": true, "id_scholarcitedby": "6637096093934733542", "cites_per_year": {"2006": 6, "2007": 28, "2008": 78, "2009": 113, "2010": 157, "2011": 200, "2012": 209, "2013": 232, "2014": 208, "2015": 182, "2016": 193, "2017": 170, "2018": 155, "2019": 81}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Get another label? Improving data quality and data mining using multiple, noisy labelers", "year": 2008, "url": "https://dl.acm.org/citation.cfm?id=1401965", "author": "Victor S Sheng and Foster Provost and Panagiotis G Ipeirotis", "pages": "614-622", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling, and focus especially on the improvement of training labels for supervised induction. With the outsourcing of small tasks becoming easier, for example via Rent-A-Coder or Amazon's Mechanical Turk, it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling, preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity, and show several main results.(i) Repeated-labeling can improve label quality and model quality, but not always.(ii) When labels are noisy, repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap.(iii) As soon as the cost \u2026</div></div></div>", "eprint": "https://archive.nyu.edu/bitstream/2451/25882/4/kdd2008.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:qjMakFHDy7sC", "citedby": 939, "_filled": true, "id_scholarcitedby": "12418718091231905022", "cites_per_year": {"2008": 3, "2009": 30, "2010": 52, "2011": 65, "2012": 94, "2013": 94, "2014": 117, "2015": 131, "2016": 106, "2017": 95, "2018": 108, "2019": 41}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Quality management on Amazon Mechanical Turk", "year": 2010, "url": "https://dl.acm.org/citation.cfm?id=1837906", "author": "Panagiotis G Ipeirotis and Foster Provost and Jing Wang", "pages": "64-67", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Crowdsourcing services, such as Amazon Mechanical Turk, allow for easy distribution of small tasks to a large number of workers. Unfortunately, since manually verifying the quality of the submitted results is hard, malicious workers often take advantage of the verification difficulty and submit answers of low quality. Currently, most requesters rely on redundancy to identify the correct answers. However, redundancy is not a panacea. Massive redundancy is expensive, increasing significantly the cost of crowdsourced solutions. Therefore, we need techniques that will accurately estimate the quality of the workers, allowing for the rejection and blocking of the low-performing workers and spammers.</div><div class=\"gsh_csp\">However, existing techniques cannot separate the true (unrecoverable) error rate from the (recoverable) biases that some workers exhibit. This lack of separation leads to incorrect assessments of a worker's quality. We present \u2026</div></div></div>", "eprint": "http://www.misrc.umn.edu/workshops/2012/fall/Ipeirotis.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:roLk4NBRz8UC", "citedby": 927, "_filled": true, "id_scholarcitedby": "4638736403341297766", "cites_per_year": {"2010": 7, "2011": 55, "2012": 85, "2013": 116, "2014": 130, "2015": 140, "2016": 119, "2017": 131, "2018": 96, "2019": 41}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Estimating the helpfulness and economic impact of product reviews: Mining text and reviewer characteristics", "year": 2011, "url": "https://ieeexplore.ieee.org/abstract/document/5590249/", "author": "Anindya Ghose and Panagiotis G Ipeirotis", "journal": "IEEE Transactions on Knowledge and Data Engineering", "volume": "23", "number": "10", "pages": "1498-1512", "publisher": "IEEE Computer Society", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">With the rapid growth of the Internet, the ability of users to create and publish content has created active electronic communities that provide a wealth of product information. However, the high volume of reviews that are typically published for a single product makes harder for individuals as well as manufacturers to locate the best reviews and understand the true underlying quality of a product. In this paper, we reexamine the impact of reviews on economic outcomes like product sales and see how different factors affect social outcomes such as their perceived usefulness. Our approach explores multiple aspects of review text, such as subjectivity levels, various measures of readability and extent of spelling errors to identify important text-based features. In addition, we also examine multiple reviewer-level features such as average usefulness of past reviews and the self-disclosed identity measures of reviewers that \u2026</div></div>", "eprint": "http://www.academia.edu/download/43849230/Estimating_the_Helpfulness_and_Economic_20160318-7408-77hdwv.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Zph67rFs4hoC", "citedby": 912, "_filled": true, "id_scholarcitedby": "10195449369436977699", "cites_per_year": {"2009": 10, "2010": 11, "2011": 31, "2012": 52, "2013": 70, "2014": 103, "2015": 122, "2016": 147, "2017": 138, "2018": 147, "2019": 75}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Approximate string joins in a database (almost) for free", "year": 2001, "url": "http://www.vldb.org/conf/2001/P491.pdf", "author": "Luis Gravano and Panagiotis G Ipeirotis and Hosagrahar Visvesvaraya Jagadish and Nick Koudas and Shanmugauelayut Muthukrishnan and Divesh Srivastava", "pages": "491-500", "publisher": "VLDB Endowment", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">String data is ubiquitous, and its management has taken on particular importance in the past few years. Approximate queries are very important on string data especially for more complex queries involving joins. This is due, for example, to the prevalence of typographical errors in data, and multiple conventions for recording attributes such as name and address. Commercial databases do not support approximate string joins directly, and it is a challenge to implement this functionality efficiently with user-defined functions (UDFs). In this paper, we develop a technique for building approximate string join capabilities on top of commercial databases by exploiting facilities already available in them. At the core, our technique relies on matching short substrings of length \u0430, called \u0430-grams, and taking into account both positions of individual matches and the total number of such matches. Our approach applies to both approximate full string matching and approximate substring matching, with a variety of possible edit distance functions. The approximate string match predicate, with a suitable edit distance threshold, can be mapped into a vanilla relational expression and optimized by conventional relational optimizers. We demonstrate experimentally the benefits of our technique over the direct use of UDFs, using commercial database systems and real data. To study the I/O and CPU behavior of approximate string join algorithms with variations in edit distance and \u0430-gram length, we also describe detailed experiments based on a prototype implementation.</div><div class=\"gsh_csp\">Permission to copy without fee all or part of this material is granted provided that the copies are not \u2026</div></div></div>", "eprint": "http://www.vldb.org/conf/2001/P491.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:u-x6o8ySG0sC", "citedby": 682, "_filled": true, "id_scholarcitedby": "4143253108621800460", "cites_per_year": {"2001": 3, "2002": 12, "2003": 26, "2004": 32, "2005": 34, "2006": 35, "2007": 35, "2008": 30, "2009": 51, "2010": 47, "2011": 60, "2012": 52, "2013": 54, "2014": 42, "2015": 41, "2016": 34, "2017": 41, "2018": 27, "2019": 14}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Analyzing the Amazon Mechanical Turk Marketplace", "year": 2010, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1688194", "author": "Panagiotis G Ipeirotis", "journal": "XRDS: Crossroads, The ACM Magazine for Students", "volume": "17", "number": "2", "pages": "16-21", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Since the concept of crowd sourcing is relatively new, many potential participants have questions about the AMT marketplace. For example, a common set of questions that pop up in an'introduction to crowd sourcing and AMT'session are the following: What type of tasks can be completed in the marketplace? How much does it cost? How fast can I get results back? How big is the AMT marketplace? The answers for these questions remain largely anecdotal and based on personal observations and experiences. To understand better what types of tasks are being completed today using crowd sourcing techniques, we started collecting data about the AMT marketplace. We present a preliminary analysis of the dataset and provide directions for interesting future research.</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/29801/4/CeDER-10-04.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:UebtZRa9Y70C", "citedby": 641, "_filled": true, "id_scholarcitedby": "986377713605968342", "cites_per_year": {"2011": 37, "2012": 58, "2013": 76, "2014": 83, "2015": 94, "2016": 89, "2017": 92, "2018": 68, "2019": 36}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Deriving the pricing power of product features by mining consumer reviews", "year": 2011, "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1370", "author": "Nikolay Archak and Anindya Ghose and Panagiotis Ipeirotis", "journal": "Management Science", "volume": "57", "number": "8", "pages": "1485-1509", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Increasingly, user-generated product reviews serve as a valuable source of information for customers making product choices online. The existing literature typically incorporates the impact of product reviews on sales based on numeric variables representing the valence and volume of reviews. In this paper, we posit that the information embedded in product reviews cannot be captured by a single scalar value. Rather, we argue that product reviews are multifaceted, and hence the textual content of product reviews is an important determinant of consumers' choices, over and above the valence and volume of reviews. To demonstrate this, we use text mining to incorporate review text in a consumer choice model by decomposing textual reviews into segments describing different product features. We estimate our model based on a unique data set from Amazon containing sales data and consumer review data for two \u2026</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/jspui/bitstream/2451/23604/4/ceder-07-05.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:yD5IFk8b50cC", "citedby": 613, "_filled": true, "id_scholarcitedby": "11247436343232612894", "cites_per_year": {"2010": 5, "2011": 10, "2012": 31, "2013": 62, "2014": 63, "2015": 60, "2016": 99, "2017": 113, "2018": 108, "2019": 46}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Demographics of Mechanical Turk", "year": 2010, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1585030", "author": "Panagiotis G Ipeirotis", "publisher": "NYU Working Paper Series", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We present the results of a survey that collected information about the demographics of participants on Amazon Mechanical Turk, together with information about their level of activity and motivation for working on Amazon Mechanical Turk. We find that approximately 50% of the workers come from the United States and 40% come from India. Country of origin tends to change the motivating reasons for workers to participate in the marketplace. Significantly more workers from India participate on Mechanical Turk because the online marketplace is a primary source of income, while in the US most workers consider Mechanical Turk a secondary source of income. While money is a primary motivating reason for workers to participate in the marketplace, workers also cite a variety of other motivating reasons, including entertainment and education.</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/jspui/bitstream/2451/29585/2/CeDER-10-01.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:g5m5HwL7SMYC", "citedby": 577, "_filled": true, "id_scholarcitedby": "8873729056826117132", "cites_per_year": {"2010": 14, "2011": 36, "2012": 51, "2013": 66, "2014": 77, "2015": 73, "2016": 87, "2017": 76, "2018": 65, "2019": 25}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Designing ranking systems for hotels on travel search engines by mining user-generated and crowd-sourced content", "year": 2012, "url": "https://pubsonline.informs.org/doi/abs/10.1287/mksc.1110.0700", "author": "Anindya Ghose and Panagiotis Ipeirotis and Beibei Li", "journal": "Marketing Science", "volume": "31", "number": "3", "pages": "493-520", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">User-generated content on social media platforms and product search engines is changing the way consumers shop for goods online. However, current product search engines fail to effectively leverage information created across diverse social media platforms. Moreover, current ranking algorithms in these product search engines tend to induce consumers to focus on one single product characteristic dimension (e.g., price, star rating). This approach largely ignores consumers' multidimensional preferences for products. In this paper, we propose to generate a ranking system that recommends products that provide, on average, the best value for the consumer's money. The key idea is that products that provide a higher surplus should be ranked higher on the screen in response to consumer queries. We use a unique data set of U.S. hotel reservations made over a three-month period through Travelocity, which we \u2026</div></div></div>", "eprint": "https://repository.upenn.edu/cgi/viewcontent.cgi?article=1209&context=oid_papers"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:TQgYirikUcIC", "citedby": 463, "_filled": true, "id_scholarcitedby": "9899611212132093583", "cites_per_year": {"2011": 4, "2012": 25, "2013": 28, "2014": 55, "2015": 70, "2016": 80, "2017": 71, "2018": 87, "2019": 39}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Designing novel review ranking systems: Predicting the usefulness and impact of reviews", "year": 2007, "url": "https://dl.acm.org/citation.cfm?id=1282158", "author": "Anindya Ghose and Panagiotis G Ipeirotis", "pages": "303-310", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">With the rapid growth of the Internet, users' ability to publish content has created active electronic communities that provide a wealth of product information. Consumers naturally gravitate to reading reviews in order to decide whether to buy a product. However, the high volume of reviews that are typically published for a single product makes it harder for individuals to locate the best reviews and understand the true underlying quality of a product based on the reviews. Similarly, the manufacturer of a product needs to identify the reviews that influence the customer base, and examine the content of these reviews. In this paper, we propose two ranking mechanisms for ranking product reviews: a consumer-oriented ranking mechanism ranks the reviews according to their expected helpfulness, and a manufacturer-oriented ranking mechanism ranks the reviews according to their expected effect on sales. Our ranking \u2026</div></div></div>", "eprint": "http://www.academia.edu/download/43848658/Designing_Novel_Review_Ranking_Systems_P20160318-24331-etle71.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Tyk-4Ss8FVUC", "citedby": 332, "_filled": true, "id_scholarcitedby": "12628184454093280325", "cites_per_year": {"2008": 10, "2009": 12, "2010": 25, "2011": 23, "2012": 40, "2013": 37, "2014": 42, "2015": 41, "2016": 46, "2017": 28, "2018": 19, "2019": 7}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Text joins in an RDBMS for web data integration", "year": 2003, "url": "https://dl.acm.org/citation.cfm?id=775166", "author": "Luis Gravano and Panagiotis G Ipeirotis and Nick Koudas and Divesh Srivastava", "pages": "90-101", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The integration of data produced and collected across autonomous, heterogeneous web services is an increasingly important and challenging problem. Due to the lack of global identifiers, the same entity (eg, a product) might have different textual representations across databases. Textual data is also often noisy because of transcription errors, incomplete information, and lack of standard formats. A fundamental task during data integration is matching of strings that refer to the same entity. In this paper, we adopt the widely used and established cosine similarity metric from the information retrieval field in order to identify potential string matches across web sources. We then use this similarity metric to characterize this key aspect of data integration as a join between relations on textual attributes, where the similarity of matches exceeds a specified threshold. Computing an exact answer to the text join can be \u2026</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.9091&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:2osOgNQ5qMEC", "citedby": 327, "_filled": true, "id_scholarcitedby": "13179750264585372430", "cites_per_year": {"2003": 1, "2004": 8, "2005": 14, "2006": 16, "2007": 25, "2008": 14, "2009": 141, "2010": 17, "2011": 16, "2012": 16, "2013": 13, "2014": 16, "2015": 6, "2016": 10, "2017": 4, "2018": 7, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Show me the money! Deriving the pricing power of product features by mining consumer reviews", "year": 2007, "url": "https://dl.acm.org/citation.cfm?id=1281202", "author": "Nikolay Archak and Anindya Ghose and Panagiotis G Ipeirotis", "pages": "56-65", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The increasing pervasiveness of the Internet has dramatically changed the way that consumers shop for goods. Consumer-generated product reviews have become a valuable source of information for customers, who read the reviews and decide whether to buy the product based on the information provided. In this paper, we use techniques that decompose the reviews into segments that evaluate the individual characteristics of a product (eg, image quality and battery life for a digital camera). Then, as a major contribution of this paper, we adapt methods from the econometrics literature, specifically the hedonic regression concept, to estimate:(a) the weight that customers place on each individual product feature,(b) the implicit evaluation score that customers assign to each feature, and (c) how these evaluations affect the revenue for a given product. Towards this goal, we develop a novel hybrid technique combining \u2026</div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2012/01/kdd2007.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:eQOLeE2rZwMC", "citedby": 259, "_filled": true, "id_scholarcitedby": "2346772377213703994", "cites_per_year": {"2007": 3, "2008": 9, "2009": 13, "2010": 26, "2011": 19, "2012": 23, "2013": 36, "2014": 30, "2015": 27, "2016": 17, "2017": 21, "2018": 26, "2019": 8}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Distributed search over the hidden web: Hierarchical database sampling and selection", "year": 2002, "url": "https://dl.acm.org/citation.cfm?id=1287404", "author": "Panagiotis G Ipeirotis and Luis Gravano", "pages": "394-405", "publisher": "VLDB Endowment", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Many valuable text databases on the web have non-crawlable contents that are\" hidden\" behind search interfaces. Metasearchers are helpful tools for searching over many such databases at once through a unified query interface. A critical task for a metasearcher to process a query efficiently and effectively is the selection of the most promising databases for the query, a task that typically relies on statistical summaries of the database contents. Unfortunately, web-accessible text databases do not generally export content summaries. In this paper, we present an algorithm to derive content summaries from\" uncooperative\" databases by using\" focused query probes,\" which adaptively zoom in on and extract documents that are representative of the topic coverage of the databases. Our content summaries are the first to include absolute document frequency estimates for the database words. We also present a novel \u2026</div></div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D893159B/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:9yKSN-GCB0IC", "citedby": 240, "_filled": true, "id_scholarcitedby": "17017493176786575080", "cites_per_year": {"2002": 1, "2003": 22, "2004": 32, "2005": 17, "2006": 15, "2007": 22, "2008": 17, "2009": 16, "2010": 14, "2011": 14, "2012": 12, "2013": 11, "2014": 8, "2015": 9, "2016": 14, "2017": 5, "2018": 7, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Probe, count, and classify: Categorizing hidden web databases", "year": 2001, "url": "https://dl.acm.org/citation.cfm?id=375671", "author": "Panagiotis G Ipeirotis and Luis Gravano and Mehran Sahami", "pages": "67-78", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The contents of many valuable web-accessible databases are only accessible through search interfaces and are hence invisible to traditional web \u201ccrawlers.\u201d Recent studies have estimated the size of this \u201chidden web\u201d to be 500 billion pages, while the size of the \u201ccrawlable\u201d web is only an estimated two billion pages. Recently, commercial web sites have started to manually organize web-accessible databases into Yahoo!-like hierarchical classification schemes. In this paper, we introduce a method for automating this classification process by using a small number of query probes. To classify a database, our algorithm does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of our technique over collections of real documents, including \u2026</div></div></div>", "eprint": "http://www.ipeirotis.com/wp-content/uploads/2012/01/sigmod2001.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:d1gkVwhDpl0C", "citedby": 212, "_filled": true, "id_scholarcitedby": "451351980277489186", "cites_per_year": {"2001": 11, "2002": 13, "2003": 16, "2004": 26, "2005": 13, "2006": 24, "2007": 13, "2008": 19, "2009": 10, "2010": 16, "2011": 8, "2012": 10, "2013": 8, "2014": 8, "2015": 6, "2016": 6, "2017": 3, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Answering general time-sensitive queries", "year": 2012, "url": "https://ieeexplore.ieee.org/abstract/document/5590248/", "author": "Wisam Dakka and Luis Gravano and Panagiotis G Ipeirotis", "journal": "IEEE Transactions on Knowledge and Data Engineering (TKDE)", "volume": "24", "number": "2", "pages": "220-235", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Time is an important dimension of relevance for a large number of searches, such as over blogs and news archives. So far, research on searching over such collections has largely focused on locating topically similar documents for a query. Unfortunately, topic similarity alone is not always sufficient for document ranking. In this paper, we observe that, for an important class of queries that we call time-sensitive queries, the publication time of the documents in a news archive is important and should be considered in conjunction with the topic similarity to derive the final document ranking. Earlier work has focused on improving retrieval for \u201crecency\u201d queries that target recent documents. We propose a more general framework for handling time-sensitive queries and we automatically identify the important time intervals that are likely to be of interest for a query. Then, we build scoring techniques that seamlessly integrate \u2026</div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/220071966_Answering_General_Time-Sensitive_Queries/links/00b7d51b09461c504f000000/Answering-General-Time-Sensitive-Queries.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:YOwf2qJgpHMC", "citedby": 167, "_filled": true, "id_scholarcitedby": "1020038989429362499", "cites_per_year": {"2009": 3, "2010": 5, "2011": 10, "2012": 21, "2013": 27, "2014": 17, "2015": 27, "2016": 23, "2017": 24, "2018": 6, "2019": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "QProber: A system for automatic classification of hidden-web databases", "year": 2003, "url": "https://dl.acm.org/citation.cfm?id=635485", "author": "Luis Gravano and Panagiotis G Ipeirotis and Mehran Sahami", "journal": "ACM Transactions on Information Systems (TOIS)", "volume": "21", "number": "1", "pages": "1-41", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The contents of many valuable Web-accessible databases are only available through search interfaces and are hence invisible to traditional Web\" crawlers.\" Recently, commercial Web sites have started to manually organize Web-accessible databases into Yahoo!-like hierarchical classification schemes. Here we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and \u2026</div></div></div>", "eprint": "http://robotics.stanford.edu/users/sahami/papers-dir/tois2003.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:UeHWp8X0CEIC", "citedby": 167, "_filled": true, "id_scholarcitedby": "2870153808886122242", "cites_per_year": {"2002": 4, "2003": 6, "2004": 15, "2005": 10, "2006": 18, "2007": 21, "2008": 12, "2009": 16, "2010": 10, "2011": 17, "2012": 11, "2013": 9, "2014": 3, "2015": 6, "2016": 2, "2017": 5}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Opinion mining using econometrics: A case study on reputation systems", "year": 2007, "url": "https://www.aclweb.org/anthology/P07-1053", "author": "Anindya Ghose and Panagiotis G. Ipeirotis and Arun Sundararajan", "pages": "416-423", "publisher": "Association of Computational Linguistics", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Deriving the polarity and strength of opinions is an important research topic, attracting significant attention over the last few years. In this work, to measure the strength and polarity of an opinion, we consider the economic context in which the opinion is evaluated, instead of using human annotators or linguistic resources. We rely on the fact that text in on-line systems influences the behavior of humans and this effect can be observed using some easy-to-measure economic variables, such as revenues or product prices. By reversing the logic, we infer the semantic orientation and strength of an opinion by tracing the changes in the associated economic variable. In effect, we use econometrics to identify the \u201ceconomic value of text\u201d and assign a \u201cdollar value\u201d to each opinion phrase, measuring sentiment effectively and without the need for manual labeling. We argue that by interpreting opinions using econometrics, we have the first objective, quantifiable, and contextsensitive evaluation of opinions. We make the discussion concrete by presenting results on the reputation system of Amazon. com. We show that user feedback affects the pricing power of merchants and by measuring their pricing power we can infer the polarity and strength of the underlying feedback postings.</div></div></div>", "eprint": "https://www.aclweb.org/anthology/P07-1053"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Y0pCki6q_DkC", "citedby": 164, "_filled": true, "id_scholarcitedby": "10297637553959899442", "cites_per_year": {"2007": 5, "2008": 18, "2009": 18, "2010": 19, "2011": 18, "2012": 19, "2013": 15, "2014": 9, "2015": 11, "2016": 15, "2017": 8, "2018": 8, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Using q-grams in a DBMS for approximate string processing", "year": 2001, "url": "https://www.researchgate.net/profile/Per-Ake_Larson/publication/220283312_New_TCDE_Chair_for_2002-2003/links/541affea0cf203f155ae7173/New-TCDE-Chair-for-2002-2003.pdf#page=30", "author": "Luis Gravano and Panagiotis G Ipeirotis and HV Jagadish and Nick Koudas and S Muthukrishnan and Lauri Pietarinen and Divesh Srivastava", "journal": "IEEE Data Engineering Bulletin", "volume": "24", "number": "1", "pages": "28-34", "publisher": "IEEE Computer Society", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">String data is ubiquitous, and its management has taken on particular importance in the past few years. Approximate queries are very important on string data. This is due, for example, to the prevalence of typographical errors in data, and multiple conventions for recording attributes such as name and address. Commercial databases do not support approximate string queries directly, and it is a challenge to implement this functionality efficiently with user-defined functions (UDFs). In this paper, we develop a technique for building approximate string processing capabilities on top of commercial databases by exploiting facilities already available in them. At the core, our technique relies on generating short substrings of length \u00d5, called \u00d5-grams, and processing them using standard methods available in the DBMS. The proposed technique enables various approximate string processing methods in a DBMS, for example approximate (sub) string selections and joins, and can even be used with a variety of possible edit distance functions. The approximate string match predicate, with a suitable edit distance threshold, can be mapped into a vanilla relational expression and optimized by conventional relational optimizers.</div></div></div>", "eprint": "https://www.researchgate.net/profile/Per-Ake_Larson/publication/220283312_New_TCDE_Chair_for_2002-2003/links/541affea0cf203f155ae7173/New-TCDE-Chair-for-2002-2003.pdf#page=30"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:IjCSPb-OGe4C", "citedby": 164, "_filled": true, "id_scholarcitedby": "4243209460607946798", "cites_per_year": {"2001": 1, "2002": 1, "2003": 5, "2004": 8, "2005": 10, "2006": 9, "2007": 9, "2008": 5, "2009": 13, "2010": 12, "2011": 19, "2012": 15, "2013": 14, "2014": 13, "2015": 15, "2016": 4, "2017": 7, "2018": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "What\u2019s the right price? pricing tasks for finishing on time", "year": 2011, "url": "https://www.aaai.org/ocs/index.php/WS/AAAIW11/paper/viewPaper/3994", "author": "Siamak Faradani and Bj\u00f6rn Hartmann and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Many practitioners currently use rules of thumb to price tasks on online labor markets. Incorrect pricing leads to task starvation or inefficient use of capital. Formal pricing policies can address these challenges. In this paper we argue that a pricing policy can be based on the trade-off between price and desired completion time. We show how this duality can lead to a better pricing policy for tasks in online labor markets. This paper makes three contributions. First, we devise an algorithm for job pricing using a survival analysis model. We then show that worker arrivals can be modeled as a non-homogeneous Poisson Process (NHPP). Finally using NHPP for worker arrivals and discrete choice models we present an abstract mathematical model that captures the dynamics of the market when full market information is presented to the task requester. This model can be used to predict completion times and pricing policies for both public and private crowds.</div></div></div>", "eprint": "https://www.aaai.org/ocs/index.php/WS/AAAIW11/paper/download/3994/4269"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:iH-uZ7U-co4C", "citedby": 127, "_filled": true, "id_scholarcitedby": "11218241044718352517", "cites_per_year": {"2011": 1, "2012": 8, "2013": 6, "2014": 21, "2015": 25, "2016": 22, "2017": 24, "2018": 17, "2019": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The dynamics of micro-task crowdsourcing: The case of amazon mturk", "year": 2015, "url": "https://dl.acm.org/citation.cfm?id=2741685", "author": "Djellel Eddine Difallah and Michele Catasta and Gianluca Demartini and Panagiotis G Ipeirotis and Philippe Cudr\u00e9-Mauroux", "pages": "238-247", "publisher": "International World Wide Web Conferences Steering Committee", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Micro-task crowdsourcing is rapidly gaining popularity among research communities and businesses as a means to leverage Human Computation in their daily operations. Unlike any other service, a crowdsourcing platform is in fact a marketplace subject to human factors that affect its performance, both in terms of speed and quality. Indeed, such factors shape the dynamics of the crowdsourcing market. For example, a known behavior of such markets is that increasing the reward of a set of tasks would lead to faster results. However, it is still unclear how different dimensions interact with each other: reward, task type, market competition, requester reputation, etc. In this paper, we adopt a data-driven approach to (A) perform a long-term analysis of a popular micro-task crowdsourcing platform and understand the evolution of its main actors (workers, requesters, and platform).(B) We leverage the main findings of our \u2026</div></div></div>", "eprint": "https://exascale.info/assets/pdf/frp1365-difallah_0.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:PuYkdpj8xa4C", "citedby": 124, "_filled": true, "id_scholarcitedby": "14650136444951070170", "cites_per_year": {"2015": 4, "2016": 17, "2017": 37, "2018": 45, "2019": 21}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Automatic construction of multifaceted browsing interfaces", "year": 2005, "url": "https://dl.acm.org/citation.cfm?id=1099738", "author": "Wisam Dakka and Panagiotis G Ipeirotis and Kenneth R Wood", "pages": "768-775", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Databases of text and text-annotated data constitute a significant fraction of the information available in electronic form. Searching and browsing are the typical ways that users locate items of interest in such databases. Interfaces that use multifaceted hierarchies represent a new powerful browsing paradigm which has been proven to be a successful complement to keyword searching. Thus far, multifaceted hierarchies have been created manually or semi-automatically, making it difficult to deploy multifaceted interfaces over a large number of databases. We present automatic and scalable methods for creation of multifaceted interfaces. Our methods are integrated with traditional relational databases and can scale well for large databases. Furthermore, we present methods for selecting the best portions of the generated hierarchies when the screen space is not sufficient for displaying all the hierarchy at once. We \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/221613581_Automatic_construction_of_multifaceted_browsing/links/0a85e530b370f52bcc000000.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:WF5omc3nYNoC", "citedby": 123, "_filled": true, "id_scholarcitedby": "16817026708586655446", "cites_per_year": {"2005": 1, "2006": 9, "2007": 4, "2008": 10, "2009": 16, "2010": 12, "2011": 22, "2012": 9, "2013": 8, "2014": 10, "2015": 7, "2016": 8, "2017": 7}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Automatic extraction of useful facet hierarchies from text databases", "year": 2008, "url": "https://ieeexplore.ieee.org/abstract/document/4497455/", "author": "Wisam Dakka and Panagiotis G Ipeirotis", "pages": "466-475", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Databases of text and text-annotated data constitute a significant fraction of the information available in electronic form. Searching and browsing are the typical ways that users locate items of interest in such databases. Faceted interfaces represent a new powerful paradigm that proved to be a successful complement to keyword searching. Thus far, the identification of the facets was either a manual procedure, or relied on apriori knowledge of the facets that can potentially appear in the underlying collection. In this paper, we present an unsupervised technique for automatic extraction of facets useful for browsing text databases. In particular, we observe, through a pilot study, that facet terms rarely appear in text documents, showing that we need external resources to identify useful facet terms. For this, we first identify important phrases in each document. Then, we expand each phrase with \";context\"; phrases using \u2026</div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/4331052_Automatic_Extraction_of_Useful_Facet_Hierarchies_from_Text_Databases/links/0c960530ba9afb0c65000000/Automatic-Extraction-of-Useful-Facet-Hierarchies-from-Text-Databases.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:_FxGoFyzp5QC", "citedby": 122, "_filled": true, "id_scholarcitedby": "8041877717075914992", "cites_per_year": {"2008": 2, "2009": 22, "2010": 12, "2011": 16, "2012": 11, "2013": 12, "2014": 11, "2015": 11, "2016": 9, "2017": 9, "2018": 4, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Examining the Impact of Ranking on Consumer Behavior and Search Engine Revenue", "year": 2014, "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2013.1828", "author": "Anindya Ghose and Panagiotis G Ipeirotis and Beibei Li", "journal": "Management Science", "volume": "60", "number": "7", "pages": "1632 - 1654", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this paper, we study the effects of three different kinds of search engine rankings on consumer behavior and search engine revenues: direct ranking effect, interaction effect between ranking and product ratings, and personalized ranking effect. We combine a hierarchical Bayesian model estimated on approximately one million online sessions from Travelocity, together with randomized experiments using a real-world hotel search engine application. Our archival data analysis and randomized experiments are consistent in demonstrating the following: (1) A consumer-utility-based ranking mechanism can lead to a significant increase in overall search engine revenue. (2) Significant interplay occurs between search engine ranking and product ratings. An inferior position on the search engine affects \u201chigher-class\u201d hotels more adversely. On the other hand, hotels with a lower customer rating are more likely to benefit \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044884_Examining_the_Impact_of_Ranking_on_Consumer_Behavior_and_Search_Engine_Revenue/links/55bf93c908aed621de139a9f/Examining-the-Impact-of-Ranking-on-Consumer-Behavior-and-Search-Engine-Revenue.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:XiSMed-E-HIC", "citedby": 117, "_filled": true, "id_scholarcitedby": "10152541740227362985", "cites_per_year": {"2013": 2, "2014": 6, "2015": 20, "2016": 25, "2017": 24, "2018": 25, "2019": 14}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Repeated Labeling Using Multiple Noisy Labelers", "year": 2014, "url": "https://link.springer.com/article/10.1007/s10618-013-0306-1", "author": "Panagiotis G. Ipeirotis and Foster Provost and Victor Sheng and Jing Wang", "journal": "Data Mining and Knowledge Discovery", "volume": "28", "number": "2", "pages": "402-441", "publisher": "Springer", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"> <div class=\"gsh_csp\">This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling, and focus especially on the improvement of training labels for supervised induction of predictive models. With the outsourcing of small tasks becoming easier, for example via Amazon\u2019s Mechanical Turk, it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling, preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity, and show several main results. (i) Repeated-labeling can improve label quality and model quality, but not always. (ii) When labels are noisy, repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap. (iii) As \u2026</div></div></div>", "eprint": "https://archive.nyu.edu/jspui/bitstream/2451/29799/2/CeDER-10-03.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:RHpTSmoSYBkC", "citedby": 117, "_filled": true, "id_scholarcitedby": "6469907402230532774", "cites_per_year": {"2013": 10, "2014": 12, "2015": 23, "2016": 28, "2017": 21, "2018": 14, "2019": 7}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The dimensions of reputation in electronic markets", "year": 2009, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=885568", "author": "Anindya Ghose and Panagiotis G. Ipeirotis and Arun Sundararajan", "journal": "Working Paper No. CeDER-06-02", "publisher": "NYU Center for Digital Economy Research", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this paper, we analyze how different dimensions of a seller's reputation affect pricing power in electronic markets. Given the interplay between buyers' trust and sellers' pricing power, we use text mining techniques to identify and structure dimensions of importance from feedback posted on reputation systems. By aggregating and scoring these dimensions based on the sentiment they contain, we use them to estimate a series of econometric models associating reputation with price premiums. We find that different dimensions do indeed affect pricing power differentially, and that a negative reputation hurts more than a positive one helps on some dimensions but not on others. We provide evidence that sellers of identical products in electronic markets differentiate themselves based on a distinguishing dimension of strength, and that buyers vary in the relative importance they place on different fulfillment characteristics. We highlight the importance of textual reputation feedback further by demonstrating that it substantially improves the performance of a classifier we have trained to predict future sales. Our results also suggest that online sellers distinguish themselves on specific and varying fulfillment characteristics that resemble the unique selling points highlighted by successful brands. We conclude by providing explicit examples of IT artifacts (buyer and seller tools) that use our interdisciplinary approach to enhance buyer trust and seller efficiency in online environments. This paper is the first study that integrates econometric, text mining and predictive modeling techniques toward a more complete analysis of the information captured by reputation \u2026</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/27740/2/ceder-06-02.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:W7OEmFMy1HYC", "citedby": 117, "_filled": true, "id_scholarcitedby": "18059963180349699761", "cites_per_year": {"2005": 2, "2006": 3, "2007": 13, "2008": 5, "2009": 17, "2010": 11, "2011": 15, "2012": 14, "2013": 4, "2014": 8, "2015": 8, "2016": 8, "2017": 3, "2018": 3, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The global opportunity in online outsourcing", "year": 1970, "url": "https://openknowledge.worldbank.org/bitstream/handle/10986/22284/The0global0opp0n0online0outsourcing.pdf", "author": "Siou Chew Kuek and Cecilia Paradi-Guilford and Toks Fayomi and Saori Imaizumi and Panos Ipeirotis and Patricia Pina and Manpreet Singh", "publisher": "World Bank, Washington, DC", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Online outsourcing (OO) has become a             promising alternative to traditional employment in today\u2019s             digital era. It has transformed where, when, and how work is             performed. For workers, this form of outsourcing has created             new opportunities to access and compete in global job             markets, from anywhere at any time, as long as they have             computer and Internet access. This study focuses on OO\u2019s             potential as a new and innovative channel for socioeconomic             development for developing country governments and             development practitioners, particularly in terms of youth             employment, services exports, and participation in the             digital economy. OO firms report that the private sector is             currently driving most of the demand, but public sector             demand for OO is a potential source of future growth. In             order to understand the opportunity for developing             countries, this study estimated the current size of the             market and projected its growth, and profiled OO work             through a combination of desk research and structured             interviews with academics, online workers, firms, and             industry analysts to better understand OO\u2019s potential impact             on human capital and employment. The study also conducted             focus group interviews with online workers in Kenya to             gather additional insight into the socioeconomic impacts of             OO, and carried out case studies in Kenya and Nigeria.</div></div>", "eprint": "https://openknowledge.worldbank.org/bitstream/handle/10986/22284/The0global0opp0n0online0outsourcing.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:bFuYayV9R1gC", "citedby": 108, "_filled": true, "id_scholarcitedby": "11324959935387893047", "cites_per_year": {"2014": 1, "2015": 13, "2016": 30, "2017": 37, "2018": 20}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Designing ranking systems for consumer reviews: The impact of review subjectivity on product sales and review quality", "year": 1970, "url": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/228618643_Designing_Ranking_Systems_for_Consumer_Reviews_The_Impact_of_Review_Subjectivity_on_Product_Sales_and_Review_Quality/links/00b7d51b09458dbae6000000.pdf", "author": "Anindya Ghose and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">With the rapid growth of the Internet, users\u2019 ability to publish content has created active electronic communities that provide a wealth of product information. Consumers naturally gravitate to reading reviews in order to decide whether to buy a product. However, the high volume of reviews that are typically published for a single product makes it harder for individuals to locate the best reviews and understand the true underlying quality of a product based on the reviews. Similarly, the manufacturer of a product wants to identify the reviews that influence the customer base, and examine the content of these reviews. In this paper we propose two ranking mechanisms for ranking product reviews: a consumer-oriented ranking mechanism ranks the reviews according to their expected helpfulness, and a manufacturer-oriented ranking mechanism ranks the reviews according to their expected effect on sales. Our ranking mechanism combines econometric analysis with text mining techniques in general, with subjectivity analysis in particular. We show that subjectivity analysis can give useful clues about the helpfulness of a review and about its impact on sales. Our results can have several implications for the market design of online opinion forums.</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/228618643_Designing_Ranking_Systems_for_Consumer_Reviews_The_Impact_of_Review_Subjectivity_on_Product_Sales_and_Review_Quality/links/00b7d51b09458dbae6000000.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:_kc_bZDykSQC", "citedby": 108, "_filled": true, "id_scholarcitedby": "4964500508564605472", "cites_per_year": {"2007": 4, "2008": 4, "2009": 2, "2010": 4, "2011": 10, "2012": 8, "2013": 13, "2014": 5, "2015": 11, "2016": 13, "2017": 10, "2018": 18, "2019": 5}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Query by document", "year": 2009, "url": "https://dl.acm.org/citation.cfm?id=1498806", "author": "Yin Yang and Nilesh Bansal and Wisam Dakka and Panagiotis Ipeirotis and Nick Koudas and Dimitris Papadias", "pages": "34-43", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We are experiencing an unprecedented increase of content contributed by users in forums such as blogs, social networking sites and microblogging services. Such abundance of content complements content on web sites and traditional media forums such as news papers, news and financial streams, and so on. Given such plethora of information there is a pressing need to cross reference information across textual services. For example, commonly we read a news item and we wonder if there are any blogs reporting related content or vice versa.</div><div class=\"gsh_csp\">In this paper, we present techniques to automate the process of cross referencing online information content. We introduce methodologies to extract phrases from a given\" query document\" to be used as queries to search interfaces with the goal to retrieve content related to the query document. In particular, we consider two techniques to extract and score key phrases. We \u2026</div></div></div>", "eprint": "http://www.ipeirotis.com/wp-content/uploads/2012/01/wsdm2009.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:kNdYIx-mwKoC", "citedby": 107, "_filled": true, "id_scholarcitedby": "5495511396746405073", "cites_per_year": {"2008": 1, "2009": 4, "2010": 7, "2011": 13, "2012": 20, "2013": 10, "2014": 21, "2015": 12, "2016": 7, "2017": 5, "2018": 4, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Quizz: targeted crowdsourcing with a billion (potential) users", "year": 2014, "url": "https://dl.acm.org/citation.cfm?id=2567988", "author": "Panagiotis G Ipeirotis and Evgeniy Gabrilovich", "pages": "143-154", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We describe Quizz, a gamified crowdsourcing system that simultaneously assesses the knowledge of users and acquires new knowledge from them. Quizz operates by asking users to complete short quizzes on specific topics; as a user answers the quiz questions, Quizz estimates the user's competence. To acquire new knowledge, Quizz also incorporates questions for which we do not have a known answer; the answers given by competent users provide useful signals for selecting the correct answers for these questions. Quizz actively tries to identify knowledgeable users on the Internet by running advertising campaigns, effectively leveraging the targeting capabilities of existing, publicly available, ad placement services. Quizz quantifies the contributions of the users using information theory and sends feedback to the advertisingsystem about each user. The feedback allows the ad targeting mechanism to further \u2026</div></div></div>", "eprint": "https://arxiv.org/pdf/1506.01062"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:H-3wYkpcA84C", "citedby": 103, "_filled": true, "id_scholarcitedby": "5685911086367190703", "cites_per_year": {"2014": 5, "2015": 20, "2016": 20, "2017": 26, "2018": 19, "2019": 12}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection", "year": 1970, "url": "http://openaccess.thecvf.com/content_cvpr_2015/html/Horn_Building_a_Bird_2015_CVPR_paper.html", "author": "Grant Van Horn and Steve Branson and Ryan Farrell and Scott Haber and Jessie Barry and Panos Ipeirotis and Pietro Perona and Serge Belongie", "pages": "595-604", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We introduce tools and methodologies to collect high quality, large scale fine-grained computer vision datasets using citizen scientists--crowd annotators who are passionate and knowledgeable about specific domains such as birds or airplanes. We worked with citizen scientists and domain experts to collect NABirds, a new high quality dataset containing 48,562 images of North American birds with 555 categories, part annotations and bounding boxes. We find that citizen scientists are significantly more accurate than Mechanical Turkers at zero cost. We worked with bird experts to measure the quality of popular datasets like CUB-200-2011 and ImageNet and found class label error rates of at least 4%. Nevertheless, we found that learning algorithms are surprisingly robust to annotation errors and this level of training data corruption can lead to an acceptably small increase in test error if the training set has sufficient size. At the same time, we found that an expert-curated high quality test set like NABirds is necessary to accurately measure the performance of fine-grained computer vision systems. We used NABirds to train a publicly available bird recognition service deployed on the web site of the Cornell Lab of Ornithology.</div></div></div>", "eprint": "http://openaccess.thecvf.com/content_cvpr_2015/papers/Horn_Building_a_Bird_2015_CVPR_paper.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:P-MJmu9ZMwQC", "citedby": 100, "_filled": true, "id_scholarcitedby": "4344715574122047059", "cites_per_year": {"2015": 5, "2016": 17, "2017": 23, "2018": 32, "2019": 23}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "To search or to crawl? Towards a query optimizer for text-centric tasks", "year": 2006, "url": "https://dl.acm.org/citation.cfm?id=1142504", "author": "Panagiotis G Ipeirotis and Eugene Agichtein and Pranay Jain and Luis Gravano", "pages": "265-276", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Text is ubiquitous and, not surprisingly, many important applications rely on textual data for a variety of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the web to locate pages about specific topics. Execution plans for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or'crawl,\" the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl-and query-based execution plans can have a substantial impact on both execution time and output\" completeness\"(eg, in terms of recall). Nevertheless, this choice is typically ad-hoc and based on heuristics or plain intuition. In this paper, we present fundamental building blocks to \u2026</div></div></div>", "eprint": "https://www.cin.ufpe.br/~mbaj/Arquivos/TEMP/sigmod2006.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:zYLM7Y9cAGgC", "citedby": 99, "_filled": true, "id_scholarcitedby": "6887446502862654577", "cites_per_year": {"2006": 3, "2007": 12, "2008": 15, "2009": 18, "2010": 9, "2011": 11, "2012": 7, "2013": 13, "2014": 5, "2015": 4}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Demographics and Dynamics of Mechanical Turk Workers", "year": 2018, "url": "https://dl.acm.org/citation.cfm?id=3159661", "author": "Djellel Difallah and Elena Filatova and Panos Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We present an analysis of the population dynamics and demographics of Amazon Mechanical Turk workers based on the results of the survey that we conducted over a period of 28 months, with more than 85K responses from 40K unique participants. The demographics survey is ongoing (as of November 2017), and the results are available at http://demographics. mturk-tracker. com: we provide an API for researchers to download the survey data. We use techniques from the field of ecology, in particular, the capture-recapture technique, to understand the size and dynamics of the underlying population. We also demonstrate how to model and account for the inherent selection biases in such surveys. Our results indicate that there are more than 100K workers available in Amazon\u00bb s crowdsourcing platform, the participation of the workers in the platform follows a heavy-tailed distribution, and at any given time there \u2026</div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2017/12/wsdmf074-difallahA.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:rAN7mHg6NlYC", "citedby": 85, "_filled": true, "id_scholarcitedby": "4436434477698742375", "cites_per_year": {"2018": 49, "2019": 36}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Beat the Machine: Challenging Humans to Find a Predictive Model\u2019s \u201cUnknown Unknowns\u201d", "year": 2015, "url": "https://dl.acm.org/citation.cfm?id=2700832", "author": "Joshua Attenberg and Panos Ipeirotis and Foster Provost", "journal": "ACM Journal on Data and Information Quality", "volume": "6", "number": "1", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We present techniques for gathering data that expose errors of automatic predictive models. In certain common settings, traditional methods for evaluating predictive models tend to miss rare but important errors\u2014most importantly, cases for which the model is confident of its prediction (but wrong). In this article, we present a system that, in a game-like setting, asks humans to identify cases that will cause the predictive model-based system to fail. Such techniques are valuable in discovering problematic cases that may not reveal themselves during the normal operation of the system and may include cases that are rare but catastrophic. We describe the design of the system, including design iterations that did not quite work. In particular, the system incentivizes humans to provide examples that are difficult for the model to handle by providing a reward proportional to the magnitude of the predictive model's error. The \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/276856305_Beat_the_Machine/links/55b7eae008aec0e5f43966a6/Beat-the-Machine.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:f13iAvnbnnYC", "citedby": 82, "_filled": true, "id_scholarcitedby": "13297645955922262897", "cites_per_year": {"2011": 1, "2012": 4, "2013": 12, "2014": 4, "2015": 5, "2016": 12, "2017": 13, "2018": 19, "2019": 12}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Managing crowdsourced human computation: A tutorial", "year": 2011, "url": "https://dl.acm.org/citation.cfm?id=1963314", "author": "Panagiotis G Ipeirotis and Praveen K Paritosh", "pages": "287-288", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The tutorial covers an emerging topic of wide interest: Crowdsourcing. Specifically, we cover areas of crowdsourcing related to managing structured and unstructured data in a web-related content. Many researchers and practitioners today see the great opportunity that becomes available through easily-available crowdsourcing platforms. However, most newcomers face the same questions: How can we manage the (noisy) crowds to generate high quality output? How to estimate the quality of the contributors? How can we best structure the tasks? How can we get results in small amounts of time and minimizing the necessary resources? How to setup the incentives? How should such crowdsourcing markets be setup? Their presented material will cover topics from a variety of fields, including computer science, statistics, economics, and psychology. Furthermore, the material will include real-life examples and case \u2026</div></div></div>", "eprint": "https://ai.google/research/pubs/pub36946.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:RGFaLdJalmkC", "citedby": 78, "_filled": true, "id_scholarcitedby": "6203357468276498176", "cites_per_year": {"2012": 6, "2013": 11, "2014": 15, "2015": 12, "2016": 12, "2017": 12, "2018": 7, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Reputation transferability in online labor markets", "year": 2015, "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2015.2217", "author": "Marios Kokkodis and Panagiotis G Ipeirotis", "journal": "Management Science", "volume": "62", "number": "6", "pages": "1687-1706", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Online workplaces such as oDesk, Amazon Mechanical Turk, and TaskRabbit have been growing in importance over the last few years. In such markets, employers post tasks on which remote contractors work and deliver the product of their work online. As in most online marketplaces, reputation mechanisms play a very important role in facilitating transactions, since they instill trust and are often predictive of the employer\u2019s future satisfaction. However, labor markets are usually highly heterogeneous in terms of available task categories; in such scenarios, past performance may not be an accurate signal of future performance. To account for this natural heterogeneity, in this work, we build models that predict the performance of a worker based on prior, category-specific feedback. Our models assume that each worker has a category-specific quality, which is latent and not directly observable; what is observable \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/281730973_Reputation_Transferability_in_Online_Labor_Markets/links/56007af308ae07629e52ae15/Reputation-Transferability-in-Online-Labor-Markets.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:WTSGYGHz1bkC", "citedby": 74, "_filled": true, "id_scholarcitedby": "1588769383808628656", "cites_per_year": {"2013": 2, "2014": 6, "2015": 9, "2016": 12, "2017": 17, "2018": 17, "2019": 10}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "When one sample is not enough: Improving text database selection using shrinkage", "year": 2004, "url": "https://dl.acm.org/citation.cfm?id=1007655", "author": "Panagiotis G Ipeirotis and Luis Gravano", "pages": "767-778", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Database selection is an important step when searching over large numbers of distributed text databases. The database selection task relies on statistical summaries of the database contents, which are not typically exported by databases. Previous research has developed algorithms for constructing an approximate content summary of a text database from a small document sample extracted via querying. Unfortunately, Zipf's law practically guarantees that content summaries built this way for any relatively large database will fail to cover many low-frequency words. Incomplete content summaries might negatively affect the database selection process, especially for short queries with infrequent words. To improve the coverage of approximate content summaries, we build on the observation that topically similar databases tend to have related vocabularies. Therefore, the approximate content summaries of topically \u2026</div></div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D8NS12QG/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:LkGwnXOMwfcC", "citedby": 66, "_filled": true, "id_scholarcitedby": "14318704049810214715", "cites_per_year": {"2004": 1, "2005": 5, "2006": 10, "2007": 5, "2008": 2, "2009": 7, "2010": 5, "2011": 11, "2012": 5, "2013": 3, "2014": 1, "2015": 5, "2016": 4, "2017": 1, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Text joins for data cleansing and integration in an RDBMS", "year": 2003, "url": "https://ieeexplore.ieee.org/abstract/document/1260850/", "author": "Luis Gravano and Panagiotis G Ipeirotis and Nick Koudas and Divesh Srivastava", "pages": "729-731", "publisher": "IEEE Computer Society", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">An organization's data records are often noisy because of transcription errors, incomplete information, lack of standard formats for textual data or combinations thereof. A fundamental task in a data cleaning system is matching textual attributes that refer to the same entity (e.g., organization name or address). This matching is effectively performed via the cosine similarity metric from the information retrieval field. For robustness and scalability, these \"text joins\" are best done inside an RDBMS, which is where the data is likely to reside. Unfortunately, computing an exact answer to a text join can be expensive. We propose an approximate, sampling-based text join execution strategy that can be robustly executed in a standard, unmodified RDBMS.</div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3773&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:ufrVoPGSRksC", "citedby": 66, "_filled": true, "id_scholarcitedby": "3872602204660455491", "cites_per_year": {"2003": 3, "2004": 10, "2005": 8, "2006": 5, "2007": 6, "2008": 2, "2009": 7, "2010": 4, "2011": 8, "2012": 5, "2013": 1, "2014": 1, "2015": 2, "2016": 2, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The EconoMining project at NYU: Studying the economic value of user-generated content on the internet", "year": 2009, "url": "https://link.springer.com/article/10.1057/rpm.2008.56", "author": "Anindya Ghose and Panagiotis Ipeirotis", "journal": "Journal of Revenue and Pricing management", "volume": "8", "number": "2-3", "pages": "241-246", "publisher": "Palgrave Macmillan UK", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"> <div class=\"gsh_csp\">An important use of the internet today is in providing a platform for consumers to disseminate information about products and services they buy, and share experiences about the merchants with whom they transact. Increasingly, online markets develop into social shopping channels, and facilitate the creation of online communities and social networks. Till date, businesses, government organisations and customers have not fully incorporated such information in their decision making and policy formulation processes, either because the potential value of the intellectual capital or appropriate techniques for measuring that value have not been identified. Increasingly, although, this publicly available digital content <i>has concrete economic value</i> that is often hidden beneath the surface. For example, online product reviews affect the buying behaviour of customers, as well as the volume of sales, positively or \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/31988717_The_EconoMining_project_at_NYU_Studying_the_economic_value_of_user-generated_content_on_the_internet/links/0deec530b377b1c4f4000000.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:HDshCWvjkbEC", "citedby": 59, "_filled": true, "id_scholarcitedby": "8801928364111140158", "cites_per_year": {"2010": 2, "2011": 7, "2012": 7, "2013": 8, "2014": 6, "2015": 8, "2016": 11, "2017": 5, "2018": 4, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Estimating the completion time of crowdsourced tasks using survival analysis models", "year": 2011, "url": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2012/01/csdm2011.pdf", "author": "Jing Wang and Siamak Faridani and Panagiotis Ipeirotis", "journal": "Crowdsourcing for search and data mining (CSDM 2011)", "volume": "31", "pages": "31-38", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In order to seamlessly integrate a human computation component (eg, Amazon Mechanical Turk) within a larger production system, we need to have some basic understanding of how long it takes to complete a task posted for completion in a crowdsourcing platform. We present an analysis of the completion time of tasks posted on Amazon Mechanical Turk, based on a dataset containing 165,368 HIT groups, with a total of 6,701,406 HITs, from 9,436 requesters, posted over a period of 15 months. We model the completion time as a stochastic process and build a statistical method for predicting the expected time for task completion. We use a survival analysis model based on Cox proportional hazards regression. We present the preliminary results of our work, showing how time-independent variables of posted tasks (eg, type of the task, price of the HIT, day posted, etc) affect completion time. We consider this a first step towards building a comprehensive optimization module that provides recommendations for pricing, posting time, in order to satisfy the constraints of the requester.</div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2012/01/csdm2011.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:hC7cP41nSMkC", "citedby": 52, "_filled": true, "id_scholarcitedby": "17989965940598799831", "cites_per_year": {"2011": 6, "2012": 2, "2013": 6, "2014": 3, "2015": 7, "2016": 12, "2017": 6, "2018": 6, "2019": 4}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Mechanical turk: The demographics", "year": 2008, "url": "http://scholar.google.com/scholar?cluster=16086664131711110051&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "A Computer Scientist in a Business School", "volume": "19"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:yeKNu01O_4gC", "citedby": 51, "_filled": true, "id_scholarcitedby": "16086664131711110051", "cites_per_year": {"2009": 1, "2010": 12, "2011": 6, "2012": 2, "2013": 5, "2014": 5, "2015": 5, "2016": 5, "2017": 6, "2018": 4}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Towards a theory model for product search", "year": 2011, "url": "https://dl.acm.org/citation.cfm?id=1963453", "author": "Beibei Li and Anindya Ghose and Panagiotis G Ipeirotis", "pages": "327-336", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">With the growing pervasiveness of the Internet, online search for products and services is constantly increasing. Most product search engines are based on adaptations of theoretical models devised for information retrieval. However, the decision mechanism that underlies the process of buying a product is different than the process of locating relevant documents or objects.</div><div class=\"gsh_csp\">We propose a theory model for product search based on expected utility theory from economics. Specifically, we propose a ranking technique in which we rank highest the products that generate the highest surplus, after the purchase. In a sense, the top ranked products are the\" best value for money\" for a specific user. Our approach builds on research on\" demand estimation\" from economics and presents a solid theoretical foundation on which further research can build on. We build algorithms that take into account consumer demographics \u2026</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.904.1738&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:-f6ydRqryjwC", "citedby": 49, "_filled": true, "id_scholarcitedby": "1088641302570606055", "cites_per_year": {"2011": 2, "2012": 9, "2013": 4, "2014": 9, "2015": 4, "2016": 6, "2017": 6, "2018": 3, "2019": 6}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Cost-Effective Quality Assurance in Crowd Labeling", "year": 2017, "url": "https://pubsonline.informs.org/doi/abs/10.1287/isre.2016.0661", "author": "Jing Wang and Panagiotis G. Ipeirotis and Foster Provost", "journal": "Information Systems Research", "volume": "28", "number": "1", "pages": "137-158", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The emergence of online <i>paid micro-crowdsourcing</i> platforms, such as Amazon Mechanical Turk, allows on-demand and at-scale distribution of tasks to human workers around the world. In such settings, online workers come and complete small tasks posted by employers, working for as long or as little as they wish, a process that eliminates the overhead of hiring (and dismissal). This flexibility introduces a different set of inefficiencies: verifying the quality of every submitted piece of work is an expensive operation that often requires the same level of effort as performing the task itself. A number of research challenges arise in such settings. How can we ensure that the submitted work is accurate? What allocation strategies can be employed to make the best use of the available labor force? How can we appropriately assess the performance of individual workers? In this paper, we consider labeling tasks and develop a \u2026</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Tiz5es2fbqcC", "citedby": 48, "_filled": true, "id_scholarcitedby": "7848186168065789870", "cites_per_year": {"2014": 9, "2015": 7, "2016": 8, "2017": 7, "2018": 9, "2019": 8}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Bonus, Disclosure, and Choice: What Motivates the Creation of High-Quality Paid Reviews?", "year": 2012, "url": "https://aisel.aisnet.org/icis2012/proceedings/DigitalNetworks/9/", "author": "Jing Wang and Anindya Ghose and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The emergence of online crowdsourcing sites has opened up new channels for third parties and companies to solicit paid reviews from people. In this paper, we investigate 1) how the introduction of monetary payments affects review quality, and 2) the impact of bonus rewards, sponsorship disclosure, and choice freedom on the quality of paid reviews. We conduct a 2\u00d7 2\u00d7 2 between-subjects experiment on Amazon Mechanical Turk. Our results indicate that there are no significant quality differences between paid and unpaid reviews. The quality of paid reviews improves by both the presence of additional performance-contingent rewards and the requirement to add disclosure text about material connections, and deteriorates by the restrictions imposed on the product set to be reviewed. These results have implications for websites and companies who are seeking legitimate reviews for their online products from paid workers.</div></div></div>", "eprint": "https://pdfs.semanticscholar.org/23cb/f679dfb6e2f316cb57b9d07c6942e33438b3.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:KxtntwgDAa4C", "citedby": 48, "_filled": true, "id_scholarcitedby": "17876866187243402739", "cites_per_year": {"2013": 3, "2014": 5, "2015": 6, "2016": 5, "2017": 8, "2018": 13, "2019": 8}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling and managing content changes in text databases", "year": 2005, "url": "https://ieeexplore.ieee.org/abstract/document/1410178/", "author": "Panagiotis G Ipeirotis and Alexandros Ntoulas and Junghoo Cho and Luis Gravano", "pages": "606-617", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Large amounts of (often valuable) information are stored in Web-accessible text databases. \"Metasearchers\" provide unified interfaces to query multiple such databases at once. For efficiency, metasearchers rely on succinct statistical summaries of the database contents to select the best databases for each query. So far, database selection research has largely assumed that databases are static, so the associated statistical summaries do not need to change over time. However, databases are rarely static and the statistical summaries that describe their contents need to be updated periodically to reflect content changes. In this paper, we first report the results of a study showing how the content summaries of 152 real Web databases evolved over a period of 52 weeks. Then, we show how to use \"survival analysis\" techniques in general, and Cox's proportional hazards regression in particular, to model database \u2026</div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D8J10B0G/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Se3iqnhoufwC", "citedby": 48, "_filled": true, "id_scholarcitedby": "13989393747650994158", "cites_per_year": {"2005": 2, "2006": 10, "2007": 10, "2008": 4, "2009": 5, "2010": 2, "2011": 2, "2012": 3, "2013": 3, "2014": 4, "2015": 1, "2016": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The new demographics of Mechanical Turk", "year": 2010, "url": "http://scholar.google.com/scholar?cluster=16893405434842387948&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "URL http://behind-the-enemy-lines. blogspot. com/2010/03/new-demographics-of-mechanical-turk. html"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:q82PccF7nXcC", "citedby": 47, "_filled": true, "id_scholarcitedby": "16893405434842387948", "cites_per_year": {"2010": 1, "2011": 8, "2012": 4, "2013": 4, "2014": 7, "2015": 3, "2016": 6, "2017": 6, "2018": 4, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Automatic discovery of useful facet terms", "year": 1970, "url": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044853_Automatic_discovery_of_useful_facet_terms/links/0a85e530b370e9691e000000/Automatic-discovery-of-useful-facet-terms.pdf", "author": "Wisam Dakka and Rishabh Dayal and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Databases of text and text-annotated data constitute a significant fraction of the information available in electronic form. Searching and browsing are the typical ways that users locate items of interest in such databases. Faceted interfaces represent a new powerful paradigm which has been proven to be a successful complement to</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044853_Automatic_discovery_of_useful_facet_terms/links/0a85e530b370e9691e000000/Automatic-discovery-of-useful-facet-terms.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:n1qY4L4uFdgC", "citedby": 43, "_filled": true, "id_scholarcitedby": "6969453891064088241", "cites_per_year": {"2007": 2, "2008": 8, "2009": 6, "2010": 6, "2011": 4, "2012": 3, "2013": 3, "2014": 4, "2015": 3, "2016": 1, "2017": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Text joins for data cleansing and integration in a relational database management system", "year": 2005, "url": "https://patents.google.com/patent/US20050027717A1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">An organization's data records are often noisy: because of transcription errors, incomplete information, and lack of standard formats for textual data. A fundamental task during data cleansing and integration is matching strings\u2014perhaps across multiple relations\u2014that refer to the same entity (eg, organization name or address). Furthermore, it is desirable to perform this matching within an RDBMS, which is where the data is likely to reside. In this paper, We adapt the widely used and established cosine similarity metric from the information retrieval field to the relational database context in order to identify potential string matches across relations. We then use this similarity metric to characterize this key aspect of data cleansing and integration as a join between relations on textual attributes, where the similarity of matches exceeds a specified threshold. Computing an exact answer to the text join can be expensive. For \u2026</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/e6/1f/ec/d2ca043966681e/US20050027717A1.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:NMxIlDl6LWMC", "citedby": 43, "_filled": true, "id_scholarcitedby": "7709901033300574486", "cites_per_year": {"2007": 3, "2008": 4, "2009": 3, "2010": 5, "2011": 5, "2012": 4, "2013": 1, "2014": 3, "2015": 3, "2016": 5, "2017": 6}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Towards an understanding of the impact of customer sentiment on product sales and review quality", "year": 2006, "url": "http://scholar.google.com/scholar?cluster=1044639943122119190&hl=en&oi=scholarr", "author": "Aindya Ghose and P Ipeirotis", "journal": "Information Technology and Systems", "volume": "12", "pages": "1-6"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:1l3MdapXzAoC", "citedby": 42, "_filled": true, "id_scholarcitedby": "1044639943122119190", "cites_per_year": {"2007": 2, "2008": 1, "2009": 1, "2010": 2, "2011": 3, "2012": 3, "2013": 6, "2014": 6, "2015": 5, "2016": 6, "2017": 1, "2018": 3, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling query-based access to text databases", "year": 1970, "url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.5023", "author": "Eugene Agichtein and Panagiotis Ipeirotis and Luis Gravano", "pages": "87--92", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">require access to such databases often resort to querying to extract relevant documents because of two main reasons. First, some text databases on the web are not\" crawlable,\" and hence the only way to retrieve their documents is via querying. Second, applications often require only a small fraction of a database's contents, so retrieving relevant documents via querying is an attractive choice from an efficiency viewpoint, even for crawlable databases. Often an application's query-based strategy starts with a small number of user-provided queries. Then, new queries are extracted--in an application-dependent way--from the documents in the initial query results, and the process iterates. The success of this common type of strategy relies on retrieved documents\" contributing\" new queries. If new documents fail to produce new queries, then the process might stall before all relevant documents are retrieved. In this paper, we develop a graph-based\" reachability\" metric that allows to characterize when an application's query-based strategy will successfully\" reach\" all documents that the application needs. We complement our metric with an efficient sampling-based technique that accurately estimates the reachability associated with a text database and an application's query-based strategy. We report preliminary experiments backing the usefulness of our metric and the accuracy of the associated estimation technique over real text databases and for two applications.</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:hqOjcs7Dif8C", "citedby": 42, "_filled": true, "id_scholarcitedby": "16072837432222253123", "cites_per_year": {"2004": 1, "2005": 3, "2006": 7, "2007": 4, "2008": 5, "2009": 2, "2010": 2, "2011": 1, "2012": 1, "2013": 2, "2014": 2, "2015": 3, "2016": 1, "2017": 4, "2018": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Towards a query optimizer for text-centric tasks", "year": 2007, "url": "https://dl.acm.org/citation.cfm?id=1292611", "author": "Panagiotis G Ipeirotis and Eugene Agichtein and Pranay Jain and Luis Gravano", "journal": "ACM Transactions on Database Systems (TODS)", "volume": "32", "number": "4", "pages": "21", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Text is ubiquitous and, not surprisingly, many important applications rely on textual data for a variety of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the Web to locate pages about specific topics. Execution plans for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or \u201ccrawl,\u201d the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl-and query-based execution plans can have a substantial impact on both execution time and output \u201ccompleteness\u201d(eg, in terms of recall). Nevertheless, this choice is typically ad hoc and based on heuristics or plain intuition. In this article, we present fundamental building blocks to \u2026</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/27821/2/CeDER-PP-2007-13.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:0EnyYjriUFMC", "citedby": 41, "_filled": true, "id_scholarcitedby": "1158668089791410859", "cites_per_year": {"2008": 7, "2009": 11, "2010": 5, "2011": 6, "2012": 1, "2013": 2, "2014": 3, "2015": 1, "2016": 1, "2017": 3, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A quality-aware optimizer for information extraction", "year": 2009, "url": "https://dl.acm.org/citation.cfm?id=1508862", "author": "Alpa Jain and Panagiotis G Ipeirotis", "journal": "ACM Transactions on Database Systems (TODS)", "volume": "34", "number": "1", "pages": "5", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">A large amount of structured information is buried in unstructured text. Information extraction systems can extract structured relations from the documents and enable sophisticated, SQL-like queries over unstructured text. Information extraction systems are not perfect and their output has imperfect precision and recall (ie, contains spurious tuples and misses good tuples). Typically, an extraction system has a set of parameters that can be used as \u201cknobs\u201d to tune the system to be either precision-or recall-oriented. Furthermore, the choice of documents processed by the extraction system also affects the quality of the extracted relation. So far, estimating the output quality of an information extraction task has been an ad hoc procedure, based mainly on heuristics. In this article, we show how to use Receiver Operating Characteristic (ROC) curves to estimate the extraction quality in a statistically robust way and show how \u2026</div></div></div>", "eprint": "https://archive.nyu.edu/jspui/bitstream/2451/25886/4/CeDER-08-02.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:4DMP91E08xMC", "citedby": 35, "_filled": true, "id_scholarcitedby": "7406608354622336909", "cites_per_year": {"2008": 1, "2009": 7, "2010": 2, "2011": 1, "2012": 2, "2013": 3, "2014": 3, "2015": 7, "2016": 7, "2017": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Managing crowdsourcing workers", "year": 2011, "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.800.5923&rep=rep1&type=pdf", "author": "Jing Wang and Panagiotis G Ipeirotis and Foster Provost", "journal": "The 2011 winter conference on business intelligence", "pages": "10-12", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The emergence of online crowdsourcing services such as Amazon Mechanical Turk, presents us huge opportunities to distribute micro-tasks at an unprecedented rate and scale. Unfortunately, the high verification cost and the unstable employment relationship give rise to opportunistic behaviors of workers, which in turn exposes the requesters to quality risks. Currently, most requesters rely on redundancy to identify the correct answers. However, existing techniques cannot separate the true (unrecoverable) error rates from the (recoverable) biases that some workers exhibit, which would lead to incorrect assessment of worker quality. Furthermore, massive redundancy is expensive, increasing significantly the cost of crowdsourced solutions.</div><div class=\"gsh_csp\">In this paper, we present an algorithm that can easily separate the true error rates from the biases. Also, we describe how to seamlessly integrate the existence of \u201cgold\u201d data for learning the quality of workers. Next, we bring up an approach for actively testing worker quality in order to quicky identify spammers or malicious workers. Finally, we present experimental results to demonstrate the performance of our proposed algorithm.</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.800.5923&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:bFI3QPDXJZMC", "citedby": 34, "_filled": true, "id_scholarcitedby": "2601146933374513796", "cites_per_year": {"2012": 2, "2013": 7, "2014": 5, "2015": 7, "2016": 5, "2017": 3, "2018": 5}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Reputation premiums in electronic peer-to-peer markets: analyzing textual feedback and network structure", "year": 2005, "url": "https://dl.acm.org/citation.cfm?id=1080207", "author": "Anindya Ghose and Panagiotis G Ipeirotis and Arun Sundararajan", "pages": "150-154", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Web-based systems that establish reputation are central to the viability of many electronic markets. We present theory that identifies the different dimensions of online reputation and characterizes their influence on the pricing power of sellers. We provide evidence that existing, numeric reputation scores conceal important seller-specific dimensions of reputation and we validate our theory further by proposing a new text mining technique that identifies and quantitatively evaluates further dimensions of importance in reputation profiles. We also suggest that the buyer-seller network contains critical reputation information that we can further exploit to improve the design of a reputation mechanism. Our experimental evaluation validates the predictions of our model using a new data set containing over 12,000 transactions for consumer software on Amazon. com's online secondary marketplace. This paper is the first \u2026</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.800.3690&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:5nxA0vEk-isC", "citedby": 33, "_filled": true, "id_scholarcitedby": "7839514139494634934", "cites_per_year": {"2006": 2, "2007": 5, "2008": 1, "2009": 3, "2010": 9, "2011": 1, "2012": 3, "2013": 2, "2014": 3, "2015": 1, "2016": 1, "2017": 1, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling consumer footprints on search engines: An interplay with social media", "year": 2018, "url": "https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2017.2991", "author": "Anindya Ghose and Panagiotis G Ipeirotis and Beibei Li", "journal": "Management Science", "volume": "65", "number": "3", "pages": "1363-1385", "publisher": "INFORMS", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">It is now well understood that social media plays an increasingly important role in consumers\u2019 decision making. However, an overload of social media content in product search engines can hinder consumers from efficiently seeking information. We propose a structural econometric model to understand consumers\u2019 preferences and costs on search engines to improve user experience under unstructured social media. Our model combines an optimal stopping framework with an individual-level random utility choice model and analyzes click behavior in conjunction with purchase choices. Our model accounts for three major constraints in a consumer\u2019s decision-making process: (1) interdependency in decision making for different alternatives, (2) sequential arrival of information revealed by click-throughs, and (3) nonnegligible search cost. Our approach allows us to jointly estimate consumers\u2019 heterogeneous \u2026</div></div></div>", "eprint": "http://www.andrew.cmu.edu/user/beibeili/Publications/BeibeiLi_Footprints_ManSci.2017_ForthComing.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:3wLP7v6BnpwC", "citedby": 28, "_filled": true, "id_scholarcitedby": "11061767524842495414", "cites_per_year": {"2013": 1, "2014": 7, "2015": 1, "2016": 5, "2017": 3, "2018": 10, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Getting more for less: Optimized crowdsourcing with dynamic tasks and goals", "year": 2015, "url": "https://dl.acm.org/citation.cfm?id=2741681", "author": "Ari Kobren and Chun How Tan and Panagiotis Ipeirotis and Evgeniy Gabrilovich", "pages": "592-602", "publisher": "International World Wide Web Conferences Steering Committee", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In crowdsourcing systems, the interests of contributing participants and system stakeholders are often not fully aligned. Participants seek to learn, be entertained, and perform easy tasks, which offer them instant gratification; system stakeholders want users to complete more difficult tasks, which bring higher value to the crowdsourced application. We directly address this problem by presenting techniques that optimize the crowdsourcing process by jointly maximizing the user longevity in the system and the true value that the system derives from user participation.</div><div class=\"gsh_csp\">We first present models that predict the\" survival probability\" of a user at any given moment, that is, the probability that a user will proceed to the next task offered by the system. We then leverage this survival model to dynamically decide what task to assign and what motivating goals to present to the user. This allows us to jointly optimize for the short term \u2026</div></div></div>", "eprint": "https://dl.acm.org/ft_gateway.cfm?id=2741681&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:DOLguN9Lh8sC", "citedby": 28, "_filled": true, "id_scholarcitedby": "16631739730454958014", "cites_per_year": {"2015": 2, "2016": 4, "2017": 7, "2018": 9, "2019": 6}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Join Optimization of Information Extraction Output: Quality Matters!", "year": 2009, "url": "https://ieeexplore.ieee.org/abstract/document/4812402/", "author": "Alpa Jain and Panagiotis G Ipeirotis and AnHai Doan and Luis Gravano", "pages": "186-197", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Information extraction (IE) systems are trained to extract specific relations from text databases. Real-world applications often require that the output of multiple IE systems be joined to produce the data of interest. To optimize the execution of a join of multiple extracted relations, it is not sufficient to consider only execution time. In fact, the quality of the join output is of critical importance: unlike in the relational world, different join execution plans can produce join results of widely different quality whenever IE systems are involved. In this paper, we develop a principled approach to understand, estimate, and incorporate output quality into the join optimization process over extracted relations. We argue that the output quality is affected by (a) the configuration of the IE systems used to process documents, (b) the document retrieval strategies used to retrieve documents, and (c) the actual join algorithm used. Our analysis \u2026</div></div>", "eprint": "http://www.cs.columbia.edu/~gravano/Papers/2009/icde09.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:M3ejUd6NZC8C", "citedby": 28, "_filled": true, "id_scholarcitedby": "3507511125834211398", "cites_per_year": {"2009": 5, "2010": 7, "2011": 4, "2012": 6, "2013": 4, "2014": 1, "2015": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "SDLIP + STARTS = SDARTS: A protocol and toolkit for metasearching", "year": 2001, "url": "https://dl.acm.org/citation.cfm?id=379496", "author": "Noah Green and Panagiotis G Ipeirotis and Luis Gravano", "pages": "207-214", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this paper we describe how we combined SDLIP and STARTS, two comple mentary protocols for searching over distributed document collections. The resulting protocol, which we call SDARTS, is simple yet expressible enough to enable building sophisticated metasearch engines. SDARTS can be viewed as an instantiation of SDLIP with metasearch-specific elements from STARTS. We also report on our experience building three SDARTS-compliant wrappers: for locally available plain-text document collections, for locally available XML document collections, and for external web-accessible collections. These wrappers were developed to be easily customizable for new collections. Our work was developed as part of Columbia University's Digital Libraries Initiative--Phase 2 (DLI2) project, which involves the departments of Computer Science, Medical Informatics, and Electrical Engineering, the Columbia \u2026</div></div></div>", "eprint": "https://files.eric.ed.gov/fulltext/ED459828.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:3fE2CSJIrl8C", "citedby": 28, "_filled": true, "id_scholarcitedby": "12018576399992906684", "cites_per_year": {"2001": 2, "2002": 4, "2003": 4, "2004": 4, "2005": 2, "2006": 1, "2007": 1, "2008": 2, "2009": 2, "2010": 1, "2011": 2, "2012": 1, "2013": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Automatic classification of text databases through query probing", "year": 2000, "url": "https://link.springer.com/chapter/10.1007/3-540-45271-0_16", "author": "Panagiotis Ipeirotis and Luis Gravano and Mehran Sahami", "pages": "245-255", "publisher": "Springer Berlin/Heidelberg", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"> <div class=\"gsh_csp\">Many text databases on the web are \u201chidden\u201d behind search interfaces, and their documents are only accessible through querying. Traditional search engines typically ignore the contents of such searchonly databases. Recently, Yahoo-like directories have started to manually organize these databases into categories that users can browse to find these valuable resources. We propose a novel strategy to automate the classification of search-only text databases. Our technique starts by training a rule-based document classifier, and then uses the classifier\u2019s rules to generate probing queries. The queries are sent to the text databases, which are then classified based on the number of matches that they produce for each query. We report some initial exploratory experiments that show that our approach is promising to automatically characterize the contents of text databases accessible on the web.</div></div></div>", "eprint": "https://arxiv.org/pdf/cs/0003043"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:ULOm3_A8WrAC", "citedby": 28, "_filled": true, "id_scholarcitedby": "5996510537384659523", "cites_per_year": {"2000": 1, "2001": 3, "2002": 4, "2003": 1, "2004": 4, "2005": 3, "2006": 2, "2007": 1, "2008": 4, "2009": 1, "2010": 2, "2011": 1, "2012": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Content and Context: Identifying the Impact of Qualitative Information on Consumer Choice", "year": 1970, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1784376", "author": "Sinan Aral and Panagiotis G Ipeirotis and Sean J Taylor", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Managers and researchers alike suspect that the vast amounts of qualitative information found in blogs, product reviews, real estate listings, news stories, analyst reports and experts\u2019 advice influence consumer behavior. But, do these kinds of qualitative information impact or rather reflect consumer choices? We argue that message content and consumer choice are endogenous, and that non-random selection and the conflation of awareness and persuasion complicate causal estimation of the impact of message content on economic decisions and outcomes. Using data on the transcribed content of 2,397 stock recommendations provided by Jim Cramer on his CNBC show Mad Money from 2005 to 2008, combined with data on Internet search volume, the content of prior news, and prior stock price and trading volume data, we show that selection bias in the stocks Cramer chooses to recommend and prior product awareness on the part of his audience create measurable upward bias in estimates of the impact of Cramer\u2019s advice on stock prices. Using Latent Dirichlet Allocation (LDA) to characterize the topical content of Cramer\u2019s speech and the content of prior news, we show that he is less persuasive when he supports his recommendations with arguments that have themselves been recently mentioned in the news. We argue that the classic sales skill of \u201cknowing what a customer needs to hear\u201d can significantly enhance the influence of qualitative information precisely because what the consumer already knows affects how they evaluate messages. The tools and techniques we develop can be put to practical use in a variety of settings where \u2026</div></div></div>", "eprint": "https://pdfs.semanticscholar.org/af71/9b4d6038f153b99d0a7f8d2765c1c5eca9e5.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:YFjsv_pBGBYC", "citedby": 27, "_filled": true, "id_scholarcitedby": "16251386313793634302", "cites_per_year": {"2011": 1, "2012": 4, "2013": 3, "2014": 5, "2015": 3, "2016": 2, "2017": 7, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Turker demographics vs. Internet demographics", "year": 2009, "url": "http://scholar.google.com/scholar?cluster=9391297623648188946&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "A Computer Scientist in a Business School", "volume": "16"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:5UUbrqTvKfUC", "citedby": 27, "_filled": true, "id_scholarcitedby": "9391297623648188946", "cites_per_year": {"2010": 4, "2011": 1, "2012": 1, "2013": 3, "2014": 1, "2015": 7, "2016": 5, "2017": 3, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Classification-aware hidden-web text database selection", "year": 2008, "url": "https://dl.acm.org/citation.cfm?id=1344412", "author": "Panagiotis G Ipeirotis and Luis Gravano", "journal": "ACM Transactions on Information Systems (TOIS)", "volume": "26", "number": "2", "pages": "6", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Many valuable text databases on the web have noncrawlable contents that are \u201chidden\u201d behind search interfaces. Metasearchers are helpful tools for searching over multiple such \u201chidden-web\u201d text databases at once through a unified query interface. An important step in the metasearching process is database selection, or determining which databases are the most relevant for a given user query. The state-of-the-art database selection techniques rely on statistical summaries of the database contents, generally including the database vocabulary and associated word frequencies. Unfortunately, hidden-web text databases typically do not export such summaries, so previous research has developed algorithms for constructing approximate content summaries from document samples extracted from the databases via querying. We present a novel \u201cfocused-probing\u201d sampling algorithm that detects the topics covered in \u2026</div></div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/14759/4/CeDER-06-04.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Wp0gIr-vW9MC", "citedby": 27, "_filled": true, "id_scholarcitedby": "2357184177976462346", "cites_per_year": {"2009": 1, "2010": 2, "2011": 7, "2012": 2, "2013": 3, "2014": 2, "2015": 4, "2016": 3, "2017": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The Need for Standardization in Crowdsourcing", "year": 1970, "url": "http://john-joseph-horton.com/papers/the_need_for_standardization_in_crowdsourcing.pdf", "author": "Panagiotis G Ipeirotis and John J Horton", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Crowdsourcing has shown itself to be well-suited for the accomplishment of certain kinds of small tasks, yet many crowdsourceable tasks still require extensive structuring and managerial effort before using a crowd is feasible. We argue that this overhead could be substantially reduced via standardization. In the same way that task standardization enabled the mass production of physical goods, standardization of basic \u201cbuilding block\u201d tasks would make crowdsourcing more scalable. Standardization would make it easier to set prices, spread best practices, build meaningful reputation systems and track quality. All of this would increase the demand for paid crowdsourcing\u2014a development we argue is positive on both efficiency and welfare grounds. Standardization would also allow more complex processes to be built out of simpler tasks while still being able to predict quality, cost and time to completion. Realizing this vision will require interdisciplinary research effort as well as buy-in from online labor platforms.</div></div></div>", "eprint": "http://john-joseph-horton.com/papers/the_need_for_standardization_in_crowdsourcing.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:NaGl4SEjCO4C", "citedby": 26, "_filled": true, "id_scholarcitedby": "5886856947441094558", "cites_per_year": {"2012": 2, "2013": 7, "2014": 2, "2015": 5, "2016": 4, "2017": 1, "2018": 4, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Hiring Behavior Models for Online Labor Markets", "year": 1970, "url": "https://dl.acm.org/citation.cfm?id=2685299", "author": "Marios Kokkodis and Panagiotis Papadimitriou and Ipeirotis Panagiotis", "pages": "223-232", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In an online labor marketplace employers post jobs, receive freelancer applications and make hiring decisions. These hiring decisions are based on the freelancer's observed (eg, education) and latent (eg, ability) characteristics. Because of the heterogeneity that appears in the observed characteristics, and the existence of latent ones, identifying and hiring the best possible applicant is a very challenging task. In this work we study and model the employer's hiring behavior. We assume that employers are utility maximizers and make rational decisions by hiring the best possible applicant at hand. Based on this premise, we propose a series of probabilistic models that estimate the hiring probability of each applicant. We train and test our models on more than 600,000 job applications obtained by oDesk. com, and we show evidence that the proposed models outperform currently in-use baselines. To get further \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/272494124_Hiring_Behavior_Models_for_Online_Labor_Markets/links/55bf90f008ae092e966699e0.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:JoHZYnTS1h4C", "citedby": 25, "_filled": true, "id_scholarcitedby": "14103849422694808489", "cites_per_year": {"2015": 6, "2016": 2, "2017": 6, "2018": 9, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Trust, but verify: Predicting contribution quality for knowledge base construction and curation", "year": 2014, "url": "https://dl.acm.org/citation.cfm?id=2556227", "author": "Chun How Tan and Eugene Agichtein and Panos Ipeirotis and Evgeniy Gabrilovich", "pages": "553-562", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The largest publicly available knowledge repositories, such as Wikipedia and Freebase, owe their existence and growth to volunteer contributors around the globe. While the majority of contributions are correct, errors can still creep in, due to editors' carelessness, misunderstanding of the schema, malice, or even lack of accepted ground truth. If left undetected, inaccuracies often degrade the experience of users and the performance of applications that rely on these knowledge repositories. We present a new method, CQUAL, for automatically predicting the quality of contributions submitted to a knowledge base. Significantly expanding upon previous work, our method holistically exploits a variety of signals, including the user's domains of expertise as reflected in her prior contribution history, and the historical accuracy rates of different types of facts. In a large-scale human evaluation, our method exhibits precision of \u2026</div></div></div>", "eprint": "https://ai.google/research/pubs/pub42023.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:aVq8r21TQD4C", "citedby": 25, "_filled": true, "id_scholarcitedby": "6157177729994723455", "cites_per_year": {"2014": 1, "2015": 5, "2016": 7, "2017": 6, "2018": 5, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Mechanical turk: Now with 40.92% spam", "year": 2010, "url": "http://scholar.google.com/scholar?cluster=12318422074972273181&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "Behind Enemy Lines blog"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:pyW8ca7W8N0C", "citedby": 24, "_filled": true, "id_scholarcitedby": "12318422074972273181", "cites_per_year": {"2011": 4, "2012": 2, "2013": 2, "2014": 2, "2015": 5, "2016": 4, "2017": 1, "2018": 1, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Crowdsourcing using mechanical turk: quality management and scalability", "year": 2011, "url": "http://www.cs.umass.edu/~wallach/workshops/nips2011css/slides/ipeirotis-nips-2011-css-workshop-invited-talk-slides.pdf", "author": "Panos Ipeirotis", "journal": "Proceedings of the 8th International Workshop on Information Integration on the Web: in conjunction with WWW", "pages": "1-1", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">\u25cf When spammer says G, it is 25% G, 25% P, 25% R, 25% X\u25cf When spammer says P, it is 25% G, 25% P, 25% R, 25% X\u25cf When spammer says R, it is 25% G, 25% P, 25% R, 25% X\u25cf When spammer says X, it is 25% G, 25% P, 25% R, 25% X [note: assume equal priors]</div></div></div>", "eprint": "http://www.cs.umass.edu/~wallach/workshops/nips2011css/slides/ipeirotis-nips-2011-css-workshop-invited-talk-slides.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:SeFeTyx0c_EC", "citedby": 21, "_filled": true, "id_scholarcitedby": "6649640417488737197", "cites_per_year": {"2011": 3, "2012": 3, "2013": 4, "2014": 3, "2015": 1, "2016": 5, "2017": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Facilitating Document Annotation using Content and Querying Value", "year": 2014, "url": "https://ieeexplore.ieee.org/abstract/document/6353425/", "author": "Eduardo J Ruiz and Vagelis Hristidis and Panagiotis G Ipeirotis", "journal": "IEEE Transactions on Knowledge and Data Engineering (TKDE)", "volume": "26", "number": "2", "pages": "336 - 349", "publisher": "IEEE Computer Society", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">A large number of organizations today generate and share textual descriptions of their products, services, and actions. Such collections of textual data contain significant amount of structured information, which remains buried in the unstructured text. While information extraction algorithms facilitate the extraction of structured relations, they are often expensive and inaccurate, especially when operating on top of text that does not contain any instances of the targeted structured information. We present a novel alternative approach that facilitates the generation of the structured metadata by identifying documents that are likely to contain information of interest and this information is going to be subsequently useful for querying the database. Our approach relies on the idea that humans are more likely to add the necessary metadata during creation time, if prompted by the interface; or that it is much easier for humans (and \u2026</div></div>", "eprint": "http://www.fziprojects.com/ieee2014java/FZIJ1425%20-%20FACILITATING%20DOCUMENT%20ANNOTATION%20USING%20CONTENT%20AND%20QUERYING%20VALUE.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:P5F9QuxV20EC", "citedby": 20, "_filled": true, "id_scholarcitedby": "9352598053330015632", "cites_per_year": {"2014": 6, "2015": 4, "2016": 7, "2017": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Building query optimizers for information extraction: The SQoUT project", "year": 2009, "url": "https://dl.acm.org/citation.cfm?id=1519108", "author": "Alpa Jain and Panagiotis Ipeirotis and Luis Gravano", "journal": "ACM SIGMOD Record", "volume": "37", "number": "4", "pages": "28-34", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Text documents often embed data that is structured in nature. This structured data is increasingly exposed using information extraction systems, which generate structured relations from documents, introducing an opportunity to process expressive, structured queries over text databases. This paper discusses our SQoUT1 project, which focuses on processing structured queries over relations extracted from text databases. We show how, in our extraction-based scenario, query processing can be decomposed into a sequence of basic steps: retrieving relevant text documents, extracting relations from the documents, and joining extracted relations for queries involving multiple relations. Each of these steps presents different alternatives and together they form a rich space of possible query execution strategies. We identify execution efficiency and output quality as the two critical properties of a query execution, and \u2026</div></div></div>", "eprint": "https://sigmodrecord.org/publications/sigmodRecord/0812/p028.special.jain.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:ZeXyd9-uunAC", "citedby": 19, "_filled": true, "id_scholarcitedby": "8808714078214036797", "cites_per_year": {"2009": 2, "2010": 2, "2011": 2, "2012": 6, "2013": 4, "2014": 1, "2015": 1, "2016": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Be a top mechanical turk worker: You need $5 and 5 minutes", "year": 2010, "url": "http://scholar.google.com/scholar?cluster=1077820320829395996&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "Blog: Behind Enemy Lines"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:abG-DnoFyZgC", "citedby": 17, "_filled": true, "id_scholarcitedby": "1077820320829395996", "cites_per_year": {"2011": 3, "2012": 1, "2013": 3, "2014": 3, "2015": 2, "2016": 2, "2017": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "System, method and computer accessible medium for determining one or more effects of rankings on consumer behavior", "year": 2015, "url": "https://patents.google.com/patent/US20150066594A1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Exemplary systems, methods and computer-accessible mediums can be provided which can receive information related to a consumer (s), and determine the search behavior of the consumer (s) based on the information and using a consumer search model that is based on heterogeneous preferences and a search cost model of a second consumer (s).</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/0b/41/8d/27443569724d65/US20150066594A1.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:ExNiBuTMO9IC", "citedby": 16, "_filled": true, "id_scholarcitedby": "8022236394313769966", "cites_per_year": {"2003": 1, "2004": 2, "2005": 1, "2006": 1, "2007": 3, "2008": 1, "2009": 2, "2010": 4, "2011": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The computer is the new sewing machine: benefits and perils of crowdsourcing", "year": 2011, "url": "https://dl.acm.org/citation.cfm?id=1963335", "author": "Praveen Paritosh and Panos Ipeirotis and Matt Cooper and Siddharth Suri", "pages": "325-326", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">There is increased participation by the developing world in the global manufacturing marketplace: the sewing machine in Bangladesh can be a means to support an entire family. Crowdsourcing for cognitive tasks consists of asking humans for questions that are otherwise impossible to answer by algorithms, eg, is this image pornographic, are these two addresses the same, what is the translation for this text in French? In the last five years, there has been an exponential growth in the size of the global cognitive marketplace: Amazon. com's Mechanical Turk has an estimated 500,000 active workers in over 100 countries, and there are dozens of other companies in this space. This turns the computer into a modern-day sewing machine, where cognitive work of various levels of difficulty will pay anywhere from 5 to 50 dollars a day. Unlike outsourcing, which usually requires college education, competence at these \u2026</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:tOudhMTPpwUC", "citedby": 15, "_filled": true, "id_scholarcitedby": "14252815068845497009", "cites_per_year": {"2011": 1, "2012": 4, "2013": 3, "2014": 2, "2015": 1, "2016": 1, "2017": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Ranked queries over sources with boolean query interfaces without ranking support", "year": 2010, "url": "https://ieeexplore.ieee.org/abstract/document/5447918/", "author": "Vagelis Hristidis and Yuheng Hu and Panagiotis G Ipeirotis", "pages": "872-875", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Many online or local data sources provide powerful querying mechanisms but limited ranking capabilities. For instance, PubMed allows users to submit highly expressive Boolean keyword queries, but ranks the query results by date only. However, a user would typically prefer a ranking by relevance, measured by an Information Retrieval (IR) ranking function. The naive approach would be to submit a disjunctive query with all query keywords, retrieve the returned documents, and then re-rank them. Unfortunately, such an operation would be very expensive due to the large number of results returned by disjunctive queries. In this paper we present algorithms that return the top results for a query, ranked according to an IR-style ranking function, while operating on top of a source with a Boolean query interface with no ranking capabilities (or a ranking capability of no interest to the end user). The algorithms generate a \u2026</div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.193.1077&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:7PzlFSSx8tAC", "citedby": 14, "_filled": true, "id_scholarcitedby": "17709617958978683005", "cites_per_year": {"2009": 1, "2010": 2, "2011": 2, "2012": 1, "2013": 2, "2014": 1, "2015": 3, "2016": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Query- vs. Crawling-based Classification of Searchable Web Databases", "year": 2002, "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.4659&rep=rep1&type=pdf", "author": "Luis Gravano and Panagiotis G.  Ipeirotis and Mehran Sahami", "journal": "IEEE Data Eng. Bull.", "volume": "25", "number": "1", "pages": "43-50", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The World-Wide Web is one of the main channels through which people currently exchange information. Unfortunately, this information is not characterized in a way that would make its semantics readily understandable by computers, which complicates building value-added services on top of the existing information. An ambitious effort that aims to facilitate the development of such services is the so-called \u201cSemantic Web.\u201d According to Berners-Lee et al.[1]:</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.4659&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:4TOpqqG69KYC", "citedby": 14, "_filled": true, "id_scholarcitedby": "8945337197361286720", "cites_per_year": {"2003": 2, "2004": 1, "2005": 2, "2006": 4, "2007": 1, "2008": 1, "2009": 1, "2010": 1, "2011": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Ridesharing and the Use of Public Transportation", "year": 1970, "url": "https://aisel.aisnet.org/icis2016/DataScience/Presentations/14/", "author": "Katherine Hoffmann and Panos Ipeirotis and Arun Sundararajan", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We investigate the effects of mobile-sourced ridesharing via platforms like Uber, Lyft, and Didi Chuxing on the use of public transit systems. Our study uses trip-level data about Uber usage in New York City, turnstile data about subway usage, and trip-level data about taxicab and shared bike usage. We find that on the surface, ridesharing and subway usage are positively correlated. Exploiting a series of exogenous shocks to the system\u2013the closing of subway stations\u2013to better isolate substitution effects, our preliminary results suggest that the average shock results in an increase of over 30% in the use of ridesharing, highlighting the potential for crowd-based systems to serve as infrastructure that helps smooth unexpected supply and demand surges. Our ongoing work studies how these substitution patterns vary with neighborhood socioeconomic indicators, and how substitution towards mobile-hailed ridesharing compares to traditional taxi and bike sharing. We hope to lay a data-driven foundation to better understand how sharing economy alternatives substitute and complement existing and future capital-intensive transit systems, and to provide a more judicious basis for assessing impacts on different population segments.</div></div></div>", "eprint": "https://pdfs.semanticscholar.org/1461/e4b58fc0a1ddce2d033bb0ebc99361df5de6.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:wTekDMGr9GkC", "citedby": 13, "_filled": true, "id_scholarcitedby": "15331032315784474232", "cites_per_year": {"2017": 2, "2018": 7, "2019": 4}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Using twitter to predict sales: A case study", "year": 2015, "url": "https://arxiv.org/abs/1503.04599", "author": "Remco Dijkman and Panagiotis Ipeirotis and Freek Aertsen and Roy van Helden", "journal": "arXiv preprint arXiv:1503.04599", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">This paper studies the relation between activity on Twitter and sales. While research exists into the relation between Tweets and movie and book sales, this paper shows that the same relations do not hold for products that receive less attention on social media. For such products, classification of Tweets is far more important to determine a relation. Also, for such products advanced statistical relations, in addition to correlation, are required to relate Twitter activity and sales. In a case study that involves Tweets and sales from a company in four countries, the paper shows how, by classifying Tweets, such relations can be identified. In particular, the paper shows evidence that positive Tweets by persons (as opposed to companies) can be used to forecast sales and that peaks in positive Tweets by persons are strongly related to an increase in sales. These results can be used to improve sales forecasts and to increase sales in marketing campaigns.</div><div class=\"gsh_csp\">Subjects: Social and Information Networks (cs. SI)</div><div class=\"gsh_csp\">Report number: BETA Working Paper WP-471</div><div class=\"gsh_csp\">Cite as: arXiv: 1503.04599 [cs. SI]</div><div class=\"gsh_csp\">(or arXiv: 1503.04599 v1 [cs. SI] for this version)</div><div class=\"gsh_csp\">Submission history</div><div class=\"gsh_csp\">From: Remco Dijkman [view email]</div><div class=\"gsh_csp\">[v1] Mon, 16 Mar 2015 10: 52: 38 UTC (144 KB)</div></div></div>", "eprint": "https://arxiv.org/pdf/1503.04599"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:FtNbRaqWXr4C", "citedby": 13, "_filled": true, "id_scholarcitedby": "17128246363646972512", "cites_per_year": {"2015": 2, "2016": 2, "2017": 4, "2018": 3, "2019": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Relevance-based Retrieval on Hidden-Web Text Databases without Ranking Support", "year": 2011, "url": "https://ieeexplore.ieee.org/abstract/document/5590244/", "author": "Vagelis Hristidis and Yuheng Hu and Panagiotis G Ipeirotis", "journal": "IEEE Transactions on Knowledge and Data Engineering (TKDE)", "volume": "23", "number": "10", "pages": "1555 - 1568", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">Many online or local data sources provide powerful querying mechanisms but limited ranking capabilities. For instance, PubMed allows users to submit highly expressive Boolean keyword queries, but ranks the query results by date only. However, a user would typically prefer a ranking by relevance, measured by an information retrieval (IR) ranking function. A naive approach would be to submit a disjunctive query with all query keywords, retrieve all the returned matching documents, and then rerank them. Unfortunately, such an operation would be very expensive due to the large number of results returned by disjunctive queries. In this paper, we present algorithms that return the top results for a query, ranked according to an IR-style ranking function, while operating on top of a source with a Boolean query interface with no ranking capabilities (or a ranking capability of no interest to the end user). The algorithms \u2026</div></div>", "eprint": "https://archivefda.dlib.nyu.edu/bitstream/2451/28302/4/paper.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:R3hNpaxXUhUC", "citedby": 13, "_filled": true, "id_scholarcitedby": "12650792246524155140", "cites_per_year": {"2012": 1, "2013": 6, "2014": 2, "2015": 1, "2016": 2, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "System, method, software arrangement and computer-accessible medium for incorporating qualitative and quantitative information into an economic model", "year": 2010, "url": "https://patents.google.com/patent/US7848979B2/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">A system, method, software arrangement and computer-accessible medium can be provided for incorporating quantitative and qualitative information into an economic model is provided. An exemplary method for analyzing qualitative information associated with a characteristic of at least one entity based on associated quantitative information, includes, obtaining first information which contains at least in part a qualitative information relating to at least one of the at least one entity; determining second information associated with at least one attribute of the characteristic obtained from the first information; obtaining third information which contains at least in part quantitative information associated with at least one of at least one entity; and establishing fourth information as a function of the second information and the third information to determine which of at least one attribute affects the characteristic. For example, an \u2026</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/1f/78/a8/ccdc4e0c6afb89/US7848979.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:blknAaTinKkC", "citedby": 13, "_filled": true, "id_scholarcitedby": "14984110415298138551", "cites_per_year": {"2009": 1, "2010": 1, "2011": 2, "2012": 3, "2013": 2, "2014": 2, "2015": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A plea to amazon: Fix mechanical turk", "year": 2010, "url": "http://scholar.google.com/scholar?cluster=14493590592899405751&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "Blog: Behind Enemy Lines"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:p2g8aNsByqUC", "citedby": 13, "_filled": true, "id_scholarcitedby": "14493590592899405751", "cites_per_year": {"2011": 3, "2012": 2, "2013": 3, "2014": 2, "2015": 1, "2016": 1, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Mechanical Turk, low wages, and the market for lemons", "year": 2010, "url": "http://scholar.google.com/scholar?cluster=3376444886209863276&hl=en&oi=scholarr", "author": "Panagiotis G Ipeirotis", "journal": "A Computer Scientist in a Business School", "volume": "27"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:LzOrNEA7mwcC", "citedby": 13, "_filled": true, "id_scholarcitedby": "3376444886209863276", "cites_per_year": {"2011": 2, "2012": 1, "2013": 2, "2014": 1, "2015": 2, "2016": 2, "2017": 2, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling and managing changes in text databases", "year": 2007, "url": "https://dl.acm.org/citation.cfm?id=1272744", "author": "Panagiotis G Ipeirotis and Alexandros Ntoulas and Junghoo Cho and Luis Gravano", "journal": "ACM Transactions on Database Systems (TODS)", "volume": "32", "number": "3", "pages": "14", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Large amounts of (often valuable) information are stored in web-accessible text databases.\u201cMetasearchers\u201d provide unified interfaces to query multiple such databases at once. For efficiency, metasearchers rely on succinct statistical summaries of the database contents to select the best databases for each query. So far, database selection research has largely assumed that databases are static, so the associated statistical summaries do not evolve over time. However, databases are rarely static and the statistical summaries that describe their contents need to be updated periodically to reflect content changes. In this article, we first report the results of a study showing how the content summaries of 152 real web databases evolved over a period of 52 weeks. Then, we show how to use \u201csurvival analysis\u201d techniques in general, and Cox's proportional hazards regression in particular, to model database changes over \u2026</div></div></div>", "eprint": "https://archive.nyu.edu/jspui/bitstream/2451/27822/2/CeDER-PP-2007-14.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:mVmsd5A6BfQC", "citedby": 13, "_filled": true, "id_scholarcitedby": "9072903138594360848", "cites_per_year": {"2009": 4, "2010": 2, "2011": 5, "2012": 1, "2013": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The utility of skills in online labor markets", "year": 1970, "url": "https://aisel.aisnet.org/icis2014/proceedings/DecisionAnalytics/15/", "author": "Marios Kokkodis and Panos Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this work we define the utility of having a certain skill in an (OLM), and we propose that this utility is strongly correlated with the level of expertise of a given worker. However, the actual level of expertise for a given skill and a given worker is both latent and dynamic. What is observable is a series of characteristics that are intuitively correlated with the level of expertise of a given skill. We propose to build a Hidden Markov Model (HMM), which estimates the latent and dynamic levels of expertise, based on the observed characteristics. We build and evaluate our approaches on a unique transactional dataset from oDesk. com. Finally, we estimate the utility of a series of skills and discuss how certain skills (eg \u2018editing\u2019) provide a higher expected payoff once a person masters them over others (eg \u2018microsoftexcel\u2019).</div></div></div>", "eprint": "http://www.ipeirotis.com/wp-content/uploads/2015/02/The-Utility-of-Skills-in-Online-Labor-Markets.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:6ScxedgR18sC", "citedby": 12, "_filled": true, "id_scholarcitedby": "12433202421122780358", "cites_per_year": {"2015": 3, "2016": 2, "2017": 3, "2018": 3, "2019": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "PERSIVAL demo: categorizing hidden-web resources.", "year": 2001, "url": "http://web6.cs.columbia.edu/~gravano/Papers/2001/jcdl01a.pdf", "author": "Panagiotis G Ipeirotis and Luis Gravano and Mehran Sahami", "pages": "454", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The information available in electronic form continues to grow at an exponential rate and this trend is expected to continue. Although traditional search engines like AltaVista can address common information needs, they ignore the often valuable information that is \u201chidden\u201d behind search interfaces, the so-called \u201chidden web.\u201d Automating the classification of \u201chidden web\u201d resources is challenging, since the contents of these collections are available only by querying, not by traditional crawling. For example, consider the PubMed medical database from the National Library of Medicine, which stores medical bibliographic information and links to full-text journals accessible through the web. This database is accessible through a query interface1. A query to PubMed with keyword \u201ccancer\u201d returns 1,313,266 matches, which are high-quality citations to medical articles, stored locally at the PubMed site. The contents of PubMed are not \u201ccrawlable\u201d by traditional search engines. Thus, a query on AltaVista for all the pages in the PubMed site with keyword \u201ccancer\u201d 2 returns only 16,380 matches. Hence, techniques that need to have the documents available for inspection are not applicable to analyze and classify the \u201chidden web\u201d resources. The ability to access these resources and organize them for subsequent use is a central component of the Digital Libraries Initiative\u2013Phase 2 (DLI2) project at Columbia University. The project is named PERSIVAL and its main goal is to provide personalized access to a distributed patient care digital library with all kinds of collections. The manual inspection and classification of these resources is a non-scalable solution \u2026</div></div></div>", "eprint": "http://web6.cs.columbia.edu/~gravano/Papers/2001/jcdl01a.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:qxL8FJ1GzNcC", "citedby": 12, "_filled": true, "id_scholarcitedby": "11292713265940485219", "cites_per_year": {"2002": 2, "2003": 2, "2004": 3, "2005": 2, "2006": 1, "2007": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "STEP: A Scalable Testing and Evaluation Platform", "year": 2014, "url": "https://www.aaai.org/ocs/index.php/HCOMP/HCOMP14/paper/view/8969", "author": "Maria Christoforaki and Panagiotis Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The emergence of online crowdsourcing sites, online work platforms, and evenMassive Open Online Courses (MOOCs), has created an increasing need for reliably evaluating the skills of the participating users in a scalable way. Many platforms already allow users to take online tests and verify their skills, but the existing approaches face many problems. First of all, cheating is very common in online testing without supervision, as the test questions often\" leak\" and become easily available online together with the answers. Second, technical skills, such as programming, require the tests to be frequently updated in order to reflect the current state-of-the-art. Third, there is very limited evaluation of the tests themselves, and how effectively they measure the skill that the users are tested for. In this paper, we present a Scalable Testing and Evaluation Platform (STEP), that allows continuous generation and evaluation of test questions. STEP leverages already available content, on Question Answering sites such as StackOverflow and re-purposes these questions to generate tests. The system utilizes a crowdsourcing component for the editing of the questions, while it uses automated techniques for identifying promising QA threads that can be successfully re-purposed for testing. This continuous question generation decreases the impact of cheating and also creates questions that are closer to the real problems that the skill holder is expected to solve in real life. STEP also leverages the use of Item Response Theory to evaluate the quality of the questions. We also use external signals about the quality of the workers. These identify the questions that have \u2026</div></div></div>", "eprint": "https://www.aaai.org/ocs/index.php/HCOMP/HCOMP14/paper/download/8969/8953"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:zaHkCSmj5XkC", "citedby": 11, "_filled": true, "id_scholarcitedby": "16862120375014810279", "cites_per_year": {"2015": 2, "2016": 5, "2017": 4}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The Impact of Information Disclosure on Stock Market Returns: The Sarbanes-Oxley Act and the Role of Media as an Information Intermediary.", "year": 2008, "url": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/228423033_The_Impact_of_Information_Disclosure_on_Stock_Market_Returns_The_Sarbanes-Oxley_Act_and_the_Role_of_Media_as_an_Information_Intermediary_Karthik/links/0a85e530b370ee0225000000/The-Impact-of-Information-Disclosure-on-Stock-Market-Returns-The-Sarbanes-Oxley-Act-and-the-Role-of-Media-as-an-Information-Intermediary-Karthik.pdf", "author": "Karthik Balakrishnan and Anindya Ghose and Panos Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The Sarbanes-Oxley (SOX) Act of 2002 is one of the, if not the, most important pieces of legislation affecting corporations traded on the US stock exchanges. While SOX does not explicitly address the issue of information security, the definition of internal control provided by the SEC, combined with the fact that the reporting systems in all firms required to comply with SOX are based on systems that promote information security and integrity does imply that more focus on information security is a necessary compliance requirement. Using a dataset on stock market abnormal returns that runs from the period 2000-2006 and consists of 300 firms, we aim to examine how the stock market reaction varies for 8-K filings and news media releases, and how this reaction has changed since the passage of the SOX Act. We hypothesize that the greater timeliness of the 8-K filings induced by SOX increases and accelerates the quality of their information disclosure and dissemination in the market. Further, we classify news articles into press-and firm-initiated articles and hypothesize that the press-initiated coverage of material events has increased in the post-SOX period. We find that the effect of firm-initiated media coverage had significant negative impact relative to press-initiated coverage on the measures of informativeness suggesting that media played a significant role during the scandal-ridden periods when the firms had poor information environment between 2002 and 2004. We also find that the timeliness of release of media articles determines the level of informativeness, suggesting that media is an information intermediary and its role acts as a substitute \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/228423033_The_Impact_of_Information_Disclosure_on_Stock_Market_Returns_The_Sarbanes-Oxley_Act_and_the_Role_of_Media_as_an_Information_Intermediary_Karthik/links/0a85e530b370ee0225000000/The-Impact-of-Information-Disclosure-on-Stock-Market-Returns-The-Sarbanes-Oxley-Act-and-the-Role-of-Media-as-an-Information-Intermediary-Karthik.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:FKYJxdYMdFIC", "citedby": 11, "_filled": true, "id_scholarcitedby": "17273293675935877281", "cites_per_year": {"2008": 1, "2009": 2, "2010": 1, "2011": 2, "2012": 2, "2013": 1, "2014": 1, "2015": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Apparatus, System, Method and Computer-Readable Medium for Performing a Product Search Using User-Generated and Crowd-Sourced Content", "year": 2012}, "source": "citations", "id_citations": "PA9La6oAAAAJ:UxriW0iASnsC", "citedby": 10, "_filled": true, "id_scholarcitedby": "15722377648650991714", "cites_per_year": {"2015": 2, "2016": 3, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Stay Elsewhere? Improving Local Search for Hotels Using Econometric Modeling and Image Classification.", "year": 1970, "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.143.5376&rep=rep1&type=pdf", "author": "Beibei Li and Anindya Ghose and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">One of the common Web searches that have a strong local component is the search for hotel accommodation. Customers try to identify hotels that satisfy particular criteria, such as service, food quality, and so on. Unfortunately, today, the travel search engines provide only rudimentary ranking facilities, typically using a single ranking criterion such as distance from city center, number of stars, price per night, or, more recently, customer reviews. This approach has obvious shortcomings. First, it ignores the multidimensional preferences of the consumer and, second, it largely ignores characteristics related to the location of the hotel, for instance, proximity to the beach or proximity to a downtown shopping area. These location-based features represent important characteristics that influence the desirability of a particular hotel. However, currently there are no established metrics that can isolate the importance of the location characteristics of hotels. In our work, we use the fact that the overall desirability of the hotel is reflected in the price of the rooms; therefore, using hedonic regressions, an established technique from econometrics, we estimate the weight that consumers place on different hotel characteristics. Furthermore, since some location-based characteristics, such as proximity to the beach, are not directly measurable, we use image classification techniques to infer such features from the satellite images of the area. Our technique is validated on a unique panel dataset consisting of 9463 different hotels located in the United States, observed over a period of 5 months. The final outcome of our analysis allows us to compute the \u201cresidual value\u201d of a \u2026</div></div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.143.5376&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:qUcmZB5y_30C", "citedby": 10, "_filled": true, "id_scholarcitedby": "18385426026739736072", "cites_per_year": {"2011": 3, "2012": 1, "2013": 1, "2014": 1, "2015": 1, "2016": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Classifying and searching hidden-web text databases", "year": 2004, "url": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2012/02/thesis.pdf", "author": "Panagiotis Ipeirotis and Luis Gravano", "pages": "4666-4666", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The World-Wide Web continues to grow. Unprecedented amounts of information are available on regular web pages and also in valuable text databases whose contents are exposed via search interfaces. Web search engines such as Google 1 provide effective access to web pages but, unfortunately, text databases are sometimes more challenging to handle. Specifically, text databases often have their contents \u201chidden\u201d behind search interfaces and their documents cannot be accessed directly through hyperlinks, which effectively makes the database contents invisible to traditional search engines. We refer to such databases as hidden-web text databases. Examples of hidden-web text databases include the Library of Congress database, the US Patent and Trademark database, the PubMed database, newspaper archives, and many other valuable sources of information. The main purpose of this thesis is to devise accurate and efficient techniques for classifying and searching hidden-web text databases, thus providing critical building blocks to enable web users to browse and search these databases as easily and efficiently as users access regular web pages via web search engines.</div><div class=\"gsh_csp\">To support browsing, it is desirable to organize text databases in a classification scheme, so that users can navigate through categories to locate databases of interest. In the past, there have been efforts to manually classify text databases into Yahoo!-like hierarchical categorization schemes. Unfortunately, manual approaches do not scale well over the web, so we present an automatic method to place databases in a classification scheme in an accurate and \u2026</div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2012/02/thesis.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:IWHjjKOFINEC", "citedby": 10, "_filled": true, "id_scholarcitedby": "2415996336689276121", "cites_per_year": {"2006": 2, "2007": 1, "2008": 2, "2009": 3, "2010": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Faceted browsing over large databases of text-annotated objects", "year": 2007, "url": "https://ieeexplore.ieee.org/abstract/document/4221837/", "author": "Wisam Dakka and Panagiotis G Ipeirotis and Kenneth R Wood", "pages": "1489-1490", "publisher": "IEEE", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\">We demonstrate a fully working system for multifaceted browsing over large collections of text-annotated data, such as annotated images, that are stored in relational databases. Typically, such databases can be browsed across multiple facets (by topic, genre, location, and so on) and previous user studies showed that multifaceted interfaces improve substantially the ability of users to identify items of interest in the database. We demonstrate a scalable system that automatically generates multifaceted browsing hierarchies on top of a relational database that stores the underlying text-annotated objects. Our system supports a wide range of ranking alternatives for selecting and displaying the best facets and the best portions of the generated hierarchies, to facilitate browsing. We combine our ranking schemes with Rapid Serial Visual Presentation (RSVP), an advanced visualization technique, which further enhances \u2026</div></div>", "eprint": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.9240&rep=rep1&type=pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:gxb_f1p9zx4C", "citedby": 9, "_filled": true, "id_scholarcitedby": "4088827207228912978", "cites_per_year": {"2008": 1, "2009": 1, "2010": 1, "2011": 2, "2012": 1, "2013": 2, "2014": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Extending SDARTS: Extracting metadata from web databases and interfacing with the Open Archives Initiative", "year": 2002, "url": "https://dl.acm.org/citation.cfm?id=544254", "author": "Panagiotis G Ipeirotis and Tom Barry and Luis Gravano", "pages": "162-170", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">SDARTS is a protocol and toolkit designed to facilitate metasearching. SDARTS combines two complementary existing protocols, SDLIP and STARTS, to define a uniform interface that collections should support for searching and exporting metasearch-related metadata. SDARTS also includes a toolkit with wrappers that are easily customized to make both local and remote document collections SDARTS-compliant. This paper describes two significant ways in which we have extended the SDARTS toolkit. First, we have added a tool that automatically builds rich content summaries for remote web collections bym probing the collections with appropriate queries. These content summaries can then be used by a metasearcher to select over which collections to evaluate a given query. Second, we have enhanced the SDARTS toolkit so that all SDARTS-compliant collections export their metadata under the emerging \u2026</div></div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D8T44581/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:9ZlFYXVOiuMC", "citedby": 9, "_filled": true, "id_scholarcitedby": "10786594490802157225", "cites_per_year": {"2003": 4, "2004": 2, "2005": 1, "2006": 1, "2007": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Methods, systems, and media for identifying errors in predictive models using annotators", "year": 2016, "url": "https://patents.google.com/patent/US9311599B1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Methods, systems, and media for identifying errors in predictive models using annotators are provided. In some embodiments, a method for evaluating predictive models in classification systems is provided, the method comprising: causing an input region to be presented to a user, where the input region receives an instance from the user that corresponds to a predictive model; retrieving a classification conducted by the predictive model for the received instance and a confidence value associated with the classification; determining whether the received instance has been incorrectly classified by the predictive model; determining a reward associated with the incorrect classification made by the predictive model in response to determining that the received instance has been incorrectly classified by the predictive model, where the reward is based on the confidence value associated with the classification of the \u2026</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/4b/21/7c/f015218c4ebaee/US9311599.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Np1obAXpBq8C", "citedby": 7, "_filled": true, "id_scholarcitedby": "7085128640553229885", "cites_per_year": {"2016": 1, "2017": 2, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Identifying effective crowdsource contributors and high quality contributions", "year": 2015, "url": "https://patents.google.com/patent/US20150242447A1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Systems and methods are disclosed for targeting effective contributors and identifying high quality contributions. For example, a method may include displaying an advertisement to a potential contributor via an advertising platform, receiving an indication that the potential contributor responded to the advertisement, generating a crowdsourcing exercise that is presented to the contributor, receiving a response (a conversion event) from the contributor to the crowdsourcing exercise, and notifying the advertising platform about the conversion event. As another example, a method may include determining a concept space for a new contribution, obtaining previously correct and incorrect contributions of the contributor in the concept space, and determining an expertise confidence score for the new contribution based on a comparison of the new contribution with the previously correct and incorrect contributions. The \u2026</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/41/ee/00/16b6b9eedccf6c/US20150242447A1.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:BKYZGPsuSFYC", "citedby": 7, "_filled": true, "id_scholarcitedby": "1740689610784131090", "cites_per_year": {"2017": 5, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Efficient Filtering on Hidden Document Streams", "year": 2014, "url": "https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8090", "author": "Eduardo J Ruiz and Vagelis Hristidis and Panagiotis G Ipeirotis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Many online services like Twitter and GNIP offer streaming programming interfaces that allow real-time information filtering based on keyword or other conditions. However, all these services specify strict access constraints, or charge a cost based on the usage. We refer to such streams as``hidden streams''to draw a parallel to the well-studied hidden Web, which similarly restricts access to the contents of a database through a querying interface. At the same time, the users' interest is often captured by complex classification models that, implicitly or explicitly, specify hundreds of keyword-based rules, along with the rules' accuracies. In this paper, we study how to best utilize a constrained streaming access interface to maximize the number of retrieved relevant items, with respect to a classifier, expressed as a set of rules. We consider two problem variants. The static version assumes that the popularity of the keywords is known and constant across time. The dynamic version lifts this assumption, and can be viewed as an exploration-vs.-exploitation problem. We show that both problems are NP-hard, and propose exact and bounded approximation algorithms for various settings, including various access constraint types. We experimentally evaluate our algorithms on real Twitter data.</div></div></div>", "eprint": "https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8090/8145"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:UEFpDhwOD2kC", "citedby": 7, "_filled": true, "id_scholarcitedby": "2239129304481319561", "cites_per_year": {"2015": 1, "2016": 5, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Search Less, Find More? Examining Limited Consumer Search with Social Media and Product Search Engines", "year": 2012, "url": "https://aisel.aisnet.org/icis2012/proceedings/ResearchMethods/11/", "author": "Anindya Ghose and Panagiotis G Ipeirotis and Beibei Li", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">With the proliferation of social media, consumers' cognitive costs during informationseeking can become non-trivial during an online shopping session. We propose a dynamic structural model of limited consumer search that combines an optimal stopping framework with an individual-level choice model. We estimate the parameters of the model using a dataset of approximately 1 million online search sessions resulting in bookings in 2117 US hotels. The model allows us to estimate the monetary value of the search costs incurred by users of product search engines in a social media context. On average, searching an extra page on a search engine costs consumers $39.15 and examining an additional offer within the same page has a cost of $6.24, respectively. A good recommendation saves consumers, on average, $9.38, whereas a bad one costs $18.54. Our policy experiment strongly supports this finding by showing that the quality of ranking can have significant impact on consumers\u2019 search efforts, and customized ranking recommendations tend to polarize the distribution of consumer search intensity. Our model-fit comparison demonstrates that the dynamic search model provides the highest overall predictive power compared to the baseline static models. Our dynamic model indicates that consumers have lower price sensitivity than a static model would have predicted, implying that consumers pay a lot of attention to non-price factors during an online hotel search.</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044875_Search_Less_Find_More_Examining_Limited_Consumer_Search_with_Social_Media_and_Product_Search_Engines/links/00b7d530b37d3c3ac9000000/Search-Less-Find-More-Examining-Limited-Consumer-Search-with-Social-Media-and-Product-Search-Engines.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:nb7KW1ujOQ8C", "citedby": 7, "_filled": true, "id_scholarcitedby": "16664620327406931126", "cites_per_year": {"2015": 1, "2016": 3, "2017": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A computer scientist in a business school", "year": 1970, "url": "http://scholar.google.com/scholar?cluster=5773312276781301203&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "Mechanical Turk vs oDesk: My experiences"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:lL5f5cZgq8MC", "citedby": 7, "_filled": true, "id_scholarcitedby": "5773312276781301203", "cites_per_year": {"2013": 1, "2014": 1, "2015": 2, "2016": 1, "2017": 1, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Why people participate on mechanical turk, now tabulated", "year": 2008, "url": "http://scholar.google.com/scholar?cluster=2641935512966752169&hl=en&oi=scholarr", "author": "PG Ipeirotis", "journal": "Zugriff am", "volume": "8", "pages": "2017"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:_u2aKJ9e-CoC", "citedby": 7, "_filled": true, "id_scholarcitedby": "2641935512966752169", "cites_per_year": {"2011": 1, "2012": 1, "2013": 3, "2014": 1, "2015": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Approximate String Joins in a Database (Almost) for Free--Erratum", "year": 1970, "url": "https://academiccommons.columbia.edu/doi/10.7916/D8M90HHN", "author": "Luis Gravano and HV Jagadish and Panagiotis G Ipeirotis and Divesh Srivastava and Nick Koudas and S Muthukrishnan", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In [GIJ+01a, GIJ+01b] we described how to use q-grams in an RDBMS to perform approximate string joins. We also showed how to implement the approximate join using plain SQL queries. Specifically, we described three filters, count filter, position filter, and length filter, which can be used to execute efficiently the approximate join. The intuition behind the count filter was that strings that are similar have many q-grams in common. In particular, two strings s1 and s2 can have up to max {| s1|,| s2|}+ q\u2212 1 common q-grams. When s1= s2, they have exactly that many q-grams in common. When s1 and s2 are within edit distance k, they share at least (max {| s1|,| s2|}+ q\u2212 1)\u2212 kq q-grams, since kq is the maximum number of q-grams that can be affected by k edit distance operations. We implemented count filter in the HAVING clause of the SQL statement in Figure 1. String pairs without enough q-grams in common are filtered out from the result. Unfortunately, this implementation of the count filter is problematic when kq is greater than or equal to max {| s1|,| s2|}+ q\u2212 1. In this case, two strings can be within edit distance k and still not share any q-grams. In such a case, the SQL statement in Figure 1 will fail to identify s1 and s2 as being within edit distance k, since there will be no q-grams from this string pair to join and count. Hence, in this case the result returned by the Figure 1 query is incomplete and suffers from \u201cfalse negatives,\u201d in contrast to our claim to the contrary in [GIJ+01a, GIJ+01b].</div><div class=\"gsh_csp\">In general, the string pairs that are omitted are pairs of short strings. Even when these strings match within small edit distance, the match tends to be meaningless (eg,\u201cIBM \u2026</div></div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D8VM4M2V/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:TiLqlu47W2oC", "citedby": 7, "_filled": true, "id_scholarcitedby": "15943122159228827026", "cites_per_year": {"2008": 1, "2009": 1, "2010": 1, "2011": 1, "2012": 1, "2013": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A report on the human computation workshop (HComp 2009)", "year": 2009, "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2009/01/HComp2009ReportFinal.pdf", "author": "Panos G Ipeirotis and Ramen Chandrasekar and Paul Bennett and Edith Law and Max Chickering and Anton Mityagin and Foster Provost and Luis von Ahn", "journal": "KDD Explorations", "volume": "11", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The first Human Computation Workshop (HComp2009) was held on June 28th, 2009, in Paris, France, collocated with SIGKDD 2009. This report summarizes the workshop, with details of the papers, demos and posters presented. The report also includes common themes, issues, and open questions that came up in the workshop.</div></div></div>", "eprint": "https://www.microsoft.com/en-us/research/wp-content/uploads/2009/01/HComp2009ReportFinal.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:hFOr9nPyWt4C", "citedby": 6, "_filled": true, "id_scholarcitedby": "12214025042336308984", "cites_per_year": {"2010": 1, "2011": 2, "2012": 2, "2013": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Why People Participate in Mechanical Turk", "year": 1970, "url": "http://scholar.google.com/scholar?cluster=3271041138993485&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "A Computer Scientist in a Business School"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:uGrg30pLAbkC", "citedby": 6, "_filled": true, "id_scholarcitedby": "3271041138993485", "cites_per_year": {"2010": 1, "2011": 1, "2012": 1, "2013": 2, "2014": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Designing ranking systems for consumer reviews: The economic impact of customer sentiment in electronic markets", "year": 1970, "url": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/242295480_Designing_Ranking_Systems_for_Consumer_Reviews_The_Economic_Impact_of_Customer_Sentiment_in_Electronic_Markets/links/0a85e530b370c91311000000.pdf", "author": "Anindya Ghose and Panagiotis Ipeirotis", "journal": "Proceedings of the 2007 International Conference on Decision Support Systems (ICDSS 2007), IIM Kolkata, January", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">With the rapid growth of the Internet, users\u2019 ability to publish content has created active electronic communities that provide a wealth of product information in the form of product reviews. However, the high volume of reviews that are typically published for a single product also have the potential to make it harder for individuals to evaluate the true underlying quality of the product based on the reviews. In such situations, the numeric data based on the average star rating of a product or on the number of reviews may not convey a lot of information on its own to a prospective buyer, and in fact buyers may naturally gravitate to reading reviews in order to come to a decision regarding the product. We conjecture that the textual content of each review may be playing an important role in influencing consumer purchase decisions and thereby affecting actual sales of the product. Hence, in this paper we investigate the veracity of this theory and propose an economics-based algorithm for ranking product reviews, according to their impact on sales and according to the extent to which other consumers perceive them as informative. We also examine the extent to which the presence of subjective (sentimental) or objective sentences in a review affects the informativeness of a review, as perceived by other users in the electronic market. Our methods can be used to predict the usefulness of a review immediately after posting thereby enhancing the speed and efficacy of decisionmaking. Our results can have several implications for market design of these online opinion forums by designing review-ranking systems that are robust to review manipulation and can be \u2026</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:738O_yMBCRsC", "citedby": 6, "_filled": true, "id_scholarcitedby": "11272256797213177586", "cites_per_year": {"2007": 1, "2008": 1, "2009": 1, "2010": 1, "2011": 1, "2012": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Task-agnostic integration of human and machine intelligence", "year": 2016, "url": "https://patents.google.com/patent/US9489636B2/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">A system combines inputs from human processing and machine processing, and employs machine learning to improve processing of individual tasks based on comparison of human processing results. Once performance of a particular task by machine processing reaches a threshold, the level of human processing used on that task is reduced.</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/3d/f8/22/c2497ef6b99d5e/US9489636.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:08ZZubdj9fEC", "citedby": 5, "_filled": true, "id_scholarcitedby": "9736267678159946288", "cites_per_year": {"2015": 1, "2016": 3}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A system for scalable and reliable technical-skill testing in online labor markets", "year": 2015, "url": "https://www.sciencedirect.com/science/article/pii/S138912861500225X", "author": "Maria Christoforaki and Panagiotis G Ipeirotis", "journal": "Computer Networks", "volume": "90", "pages": "110-120", "publisher": "Elsevier", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div><div><div class=\"gsh_csp\">The emergence of online labor platforms, online crowdsourcing sites, and even Massive Open Online Courses (MOOCs), has created an increasing need for reliably evaluating the skills of the participating users (e.g., \u201cdoes a candidate know Java\u201d) in a scalable way. Many platforms already allow job candidates to take online tests to assess their competence in a variety of technical topics. However the existing approaches face many problems. First, cheating is very common in online testing without supervision, as the test questions often \u201cleak\u201d and become easily available online along with the answers. Second, technical-skills, such as programming, require the tests to be frequently updated in order to reflect the current state-of-the-art. Third, there is very limited evaluation of the tests themselves, and how effectively they measure the skill that the users are tested for.</div><div class=\"gsh_csp\">In this article we present a platform, which \u2026</div></div></div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2015/06/comnet-step.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:i6LplTXqhpIC", "citedby": 5, "_filled": true, "id_scholarcitedby": "14112687226154413512", "cites_per_year": {"2016": 3, "2017": 1, "2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Visualizations of the oDesk \u2018oConomy:\u2019Exploring Our World of Work", "year": 1970, "url": "http://scholar.google.com/scholar?cluster=10434182457015436004&hl=en&oi=scholarr", "author": "Panos Ipeirotis and J Horton", "journal": "Upwork Blog"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:xEMdJR0kL_sC", "citedby": 5, "_filled": true, "id_scholarcitedby": "10434182457015436004", "cites_per_year": {"2015": 3, "2016": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Examining the Impact of Search Engine Ranking and Personalization on Consumer Behavior: Combining Bayesian Modeling with Randomized Field Experiments", "year": 2011, "url": "http://www.ipeirotis.com/wp-content/uploads/2012/01/wise2011_SearchDesign.pdf", "author": "Anindya Ghose and Panagiotis G. Ipeirotis and Beibei Li", "journal": "Workshop on Information Systems and Economics (WISE 2011)", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this paper, we examine how different ranking and personalization mechanisms on product search engines influence consumer online search and purchase behavior. To investigate these effects, we combine archival data analysis with randomized field experiments. Our archival data analysis is based on a unique dataset containing approximately 1 million online sessions from Travelocity over a 3-month period. Using a hierarchical Bayesian model, we first jointly estimate the relationship among consumer click and purchase behavior, and search engine ranking decisions. To evaluate the causal effect of search engine interface on user behavior, we conduct randomized field experiments. The field experiments are based on a real-world hotel search engine application designed and built by us. By manipulating the default ranking method of search results, and by enabling or disabling a variety of personalization features on the hotel search engine website, we are able to empirically identify the causal impact of search engines on consumers\u2019 online click and purchase behavior.</div><div class=\"gsh_csp\">The archival data analysis and the randomized experiments are consistent in demonstrating that ranking has a significant effect on consumer click and purchase behavior. We find that hotels with a higher reputation for providing superior services are more adversely affected by an inferior screen position. In addition, a consumer utility-based ranking mechanism yields the highest click and purchase propensities in comparison to existing benchmark systems such as ranking based on price or customer ratings. Our randomized experiments on the impact of active vs. passive \u2026</div></div></div>", "eprint": "http://www.ipeirotis.com/wp-content/uploads/2012/01/wise2011_SearchDesign.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:cFHS6HbyZ2cC", "citedby": 5, "_filled": true, "id_scholarcitedby": "1520251994469078583", "cites_per_year": {"2012": 1, "2013": 1, "2014": 1, "2015": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling volatility in prediction markets", "year": 2009, "url": "https://dl.acm.org/citation.cfm?id=1566414", "author": "Nikolay Archak and Panagiotis G Ipeirotis", "pages": "275-284", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">There is significant experimental evidence that prediction markets are efficient mechanisms for aggregating information and are more accurate in forecasting events than traditional forecasting methods, such as polls. Interpretation of prediction market prices as probabilities has been extensively studied in the literature. However there is little research on the volatility of prediction market prices. Given that volatility is fundamental in estimating significance of price movements, it is important to have a better understanding of the volatility of the contract prices.</div><div class=\"gsh_csp\">This paper presents a model of a prediction market with binary payoff on a competitive event involving two parties. In our model, each party has a latent underlying\" ability\" process that describes its ability to win and evolves as an Ito diffusion. We show that, if the prediction market for this event is efficient and unbiased, the price of the corresponding contract also \u2026</div></div></div>", "eprint": "https://archive.nyu.edu/jspui/bitstream/2451/27716/4/CeDER-08-07.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:mB3voiENLucC", "citedby": 5, "_filled": true, "id_scholarcitedby": "13059628597193880888", "cites_per_year": {"2010": 1, "2011": 1, "2012": 1, "2013": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Summarizing and searching hidden-web databases hierarchically using focused probes", "year": 1970, "url": "https://academiccommons.columbia.edu/doi/10.7916/D82Z1HQ9", "author": "Panagiotis G Ipeirotis and Luis Gravano", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Many valuable text databases on the web have non-crawlable contents that are \u201chidden\u201d behind search interfaces. Metasearchers are helpful tools for searching over many such databases at once through a unified query interface. A critical task for a metasearcher to process a query efficiently and effectively is the selection of the most promising databases for the query, a task that typically relies on statistical summaries of the database contents. Unfortunately, web-accessible text databases do not generally export content summaries. In this paper, we present an algorithm to derive content summaries from \u201cuncooperative\u201d databases by using \u201cfocused query probes,\u201d which adaptively zoom in on and extract documents that are representative of the topic coverage of the databases. The content summaries that result from this algorithm are efficient to derive and more accurate than those from previously proposed probing techniques for content-summary extraction. We also present a novel database selection algorithm that exploits both the extracted content summaries and a hierarchical classification of the databases, automatically derived during probing, to produce accurate results even for imperfect content summaries. Finally, we evaluate our techniques thoroughly using a variety of databases, including 50 real web-accessible text databases.</div></div></div>", "eprint": "https://academiccommons.columbia.edu/doi/10.7916/D8DV1X1C/download"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:xtRiw3GOFMkC", "citedby": 5, "_filled": true, "id_scholarcitedby": "16554727440279622658", "cites_per_year": {"2002": 1, "2003": 2, "2004": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Do mechanical turk workers lie about their location", "year": 2011, "url": "http://scholar.google.com/scholar?cluster=17009151796338767036&hl=en&oi=scholarr", "author": "Panos Ipeirotis", "journal": "A Computer Scientist in a Business School"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:RZBefGmQYygC", "citedby": 4, "_filled": true, "id_scholarcitedby": "17009151796338767036", "cites_per_year": {"2011": 1, "2012": 1, "2013": 2}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "A demo search engine for products", "year": 2011, "url": "https://dl.acm.org/citation.cfm?id=1963297", "author": "Beibei Li and Anindya Ghose and Panagiotis G Ipeirotis", "pages": "233-236", "publisher": "ACM", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Most product search engines today build on models of relevance devised for information retrieval. However, the decision mechanism that underlies the process of buying a product is different than the process of locating relevant documents or objects. We propose a theory model for product search based on expected utility theory from economics. Specifically, we propose a ranking technique in which we rank highest the products that generate the highest surplus, after the purchase. We instantiate our research by building a demo search engine for hotels that takes into account consumer heterogeneous preferences, and also accounts for the varying hotel price. Moreover, we achieve this without explicitly asking the preferences or purchasing histories of individual consumers but by using aggregate demand data. This new ranking system is able to recommend consumers products with\" best value for money\" in a \u2026</div></div></div>", "eprint": "https://www.researchgate.net/profile/Beibei_Li3/publication/221023945_A_demo_search_engine_for_products/links/02bfe5111248fe3427000000.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:isC4tDSrTZIC", "citedby": 3, "_filled": true, "id_scholarcitedby": "16458068970404464149", "cites_per_year": {"2012": 1, "2013": 1, "2014": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The Computer is the New Sewing Machine: Benefits and Perils of Crowdsourcing", "year": 1970, "url": "http://www.ramb.ethz.ch/CDstore/www2011/companion/p325.pdf", "author": "Matt Cooper and Panos Ipeirotis and Siddharth Suri", "journal": "Panel at the 20th International World-Wide Web Conference, March", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\">Crowdsourcing for cognitive tasks consists of asking humans for questions that are otherwise \nimpossible to answer by algorithms, eg, is this image pornographic, are these two addresses \nthe same, what is the translation for this text in French? In the last five years, there has been an \nexponential growth in the size of the global cognitive marketplace: Amazon.com's Mechanical \nTurk has an estimated 500,000 active workers in over 100 countries, and there are dozens of \nother companies in this space \u2026 This turns the computer into a modern-day sewing \nmachine, where cognitive work of various levels of difficulty will pay anywhere from 5 to 50 dollars \na day. Unlike outsourcing, which usually requires college education, competence at these tasks \nmight be a month or even less of training. At its best, this could be a powerful bootstrap for a billion \npeople. At its worst, this can lead to unprecedented exploitation.  </div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:pZ2CosqRuhkC", "citedby": 2, "_filled": true, "id_scholarcitedby": "4984100411689919125", "cites_per_year": {"2016": 1, "2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Towards Automating the Pricing Power of Product Attributes: An Analysis of Online Product Reviews", "year": 1970, "url": "http://www.ipeirotis.com/wp-content/uploads/2012/01/Winter_BI_Panagiotis.pdf", "author": "Nikolay Archak and Anindya Ghose and P Ipeirotis", "journal": "Winter Business Intelligence Conference", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The Internet has had a profound impact on at least two areas of life\u2013the way people shop, and the way they exchange information. Both are relevant to consumer product reviews posted in IT-enabled electronic markets. Online consumer product reviews provide information that can facilitate economic exchange, which is the main purpose of electronic marketplaces. In particular, many users like to learn about the experiences of other customers with a product before purchasing the product. Online product reviews have been shown to influence product sales such as books and movies (Chevalier &amp; Mayzlin 2006). Similarly, the volume of discussion about a product in blogs has recently been shown to correlate with the product's financial performance (Gruhl, Guha, Kumar, Novak &amp; Tomkins 2005). We aim to extend these studies in different ways.</div><div class=\"gsh_csp\">At a broader level, we plan to empirically estimate how the textual content \u2026</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:n8FNryW2AHIC", "citedby": 2, "_filled": true, "id_scholarcitedby": "4337121473799122428", "cites_per_year": {"2013": 1, "2014": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "System, method and computer-accessible medium for scalable testing and evaluation", "year": 2016, "url": "https://patents.google.com/patent/US20160019803A1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">An exemplary system, method and computer-accessible medium can be provided that can be used, for example, for evaluating a test question (s) for a test (s), which can include receiving information related to a content (s), mapping the content (s) to a skill (s), and evaluating the content (s) as the test question (s) so as to test an ability of user (s) at the skill (s).</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/52/59/65/14227f340cf509/US20160019803A1.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:qOpkhvVCMvUC", "citedby": 1, "_filled": true, "id_scholarcitedby": "4812881314551486273", "cites_per_year": {"2018": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "TOWARDS DESIGNING RANKING SYSTEMS FOR HOTELS ON TRAVEL SEARCH ENGINES: COMBINING TEXT MINING AND IMAGE CLASSIFICATION WITH ECONOMETRICS", "year": 2009, "url": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044864_TOWARDS_DESIGNING_RANKING_SYSTEMS_FOR_HOTELS_ON_TRAVEL_SEARCH_ENGINES_COMBINING_TEXT_MINING_AND_IMAGE_CLASSIFICATION_WITH_ECONOMETRICS/links/55bfd48108aec0e5f4476a30/TOWARDS-DESIGNING-RANKING-SYSTEMS-FOR-HOTELS-ON-TRAVEL-SEARCH-ENGINES-COMBINING-TEXT-MINING-AND-IMAGE-CLASSIFICATION-WITH-ECONOMETRICS.pdf", "author": "Anindya Ghose and Panagiotis G Ipeirotis and Beibei Li", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In this paper, we empirically estimate the economic value of different hotel characteristics, especially the location-based and service-based characteristics given the associated local infrastructure. We build a random coefficients-based structural model taking into consideration the multiple-levels of consumer heterogeneity introduced by different travel contexts and different hotel characteristics. We estimate this econometric model with a unique dataset of hotel reservations located in the US over 3 months and user-generated content data that was processed based on techniques from text mining, image classification, and on-demand annotations. This enables us to infer the economic significance of various hotel characteristics. We then propose to design a new hotel ranking system based on the empirical estimates that take into account the multi-dimensional preferences of customers and imputes consumer surplus from transactions for a given hotel. By doing so, we are able to provide customers with the \u201cbest value for money\u201d hotels. Based on blind tests of users from Amazon Mechanical Turk, we test our ranking system with some benchmark hotel ranking systems. We find that our system performs significantly better than existing ones. This suggests that our inter-disciplinary approach has the potential to improve the quality of hotel search.</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/237044864_TOWARDS_DESIGNING_RANKING_SYSTEMS_FOR_HOTELS_ON_TRAVEL_SEARCH_ENGINES_COMBINING_TEXT_MINING_AND_IMAGE_CLASSIFICATION_WITH_ECONOMETRICS/links/55bfd48108aec0e5f4476a30/TOWARDS-DESIGNING-RANKING-SYSTEMS-FOR-HOTELS-ON-TRAVEL-SEARCH-ENGINES-COMBINING-TEXT-MINING-AND-IMAGE-CLASSIFICATION-WITH-ECONOMETRICS.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:zA6iFVUQeVQC", "citedby": 1, "_filled": true, "id_scholarcitedby": "1293354607023547259", "cites_per_year": {"2010": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Taxonomy design", "year": 1970, "url": "https://link.springer.com/chapter/10.1007/978-3-642-02359-0_7", "author": "Wisam Dakka and Panagiotis Ipeirotis and Giovanni Maria Sacco", "pages": "175-213", "publisher": "Springer, Berlin, Heidelberg", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"> <div class=\"gsh_csp\">This chapter discusses the design of taxonomies to be used in dynamic taxonomy systems. Although the only actual requirement of dynamic taxonomies is a multidimensional classification, an organization by facets is normally used.</div> <div class=\"gsh_csp\">The first section provides guidelines for the design of DT taxonomies, which include the automatic construction from structured data, and the retrofitting of traditional monodimensional taxonomies.</div> <div class=\"gsh_csp\">The second section shows how a faceted taxonomy can be automatically extracted from the infobase itself when objects are textual or are described by textual captions or tags.</div></div></div>", "eprint": "https://www.researchgate.net/profile/Panos_Ipeirotis/publication/226381399_Taxonomy_Design/links/0a85e530b370f12be0000000/Taxonomy-Design.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:M05iB0D1s5AC", "citedby": 1, "_filled": true, "id_scholarcitedby": "10712097918361380304", "cites_per_year": {"2009": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "The dynamics of micro-task crowdsourcing", "url": "http://www.ipeirotis.com/wp-content/uploads/2015/02/frp1365-difallah.pdf", "author": "D Difallah and Michele Catasta and Gianluca Demartini and P Ipeirotis and Philippe Cudr\u00e9-Mauroux", "journal": "WWW'15 Proc. 24thh Int. Conf. World Wide Web", "pages": "238-247", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Micro-task crowdsourcing is rapidly gaining popularity among research communities and businesses as a means to leverage Human Computation in their daily operations. Unlike any other service, a crowdsourcing platform is in fact a marketplace subject to human factors that affect its performance, both in terms of speed and quality. Indeed, such factors shape the dynamics of the crowdsourcing market. For example, a known behavior of such markets is that increasing the reward of a set of tasks would lead to faster results. However, it is still unclear how different dimensions interact with each other: reward, task type, market competition, requester reputation, etc. In this paper, we adopt a data-driven approach to (A) perform a long-term analysis of a popular micro-task crowdsourcing platform and understand the evolution of its main actors (workers, requesters, tasks, and platform).(B) We leverage the main findings of our five year log analysis to propose features used in a predictive model aiming at determining the expected performance of any batch at a specific point in time. We show that the number of tasks left in a batch and how recent the batch is are two key features of the prediction.(C) Finally, we conduct an analysis of the demand (new tasks posted by the requesters) and supply (number of tasks completed by the workforce) and show how they affect task prices on the marketplace.</div></div></div>", "eprint": "http://www.ipeirotis.com/wp-content/uploads/2015/02/frp1365-difallah.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Q17yWvk9gpwC", "citedby": 1, "_filled": true, "id_scholarcitedby": "3659796962353553730", "cites_per_year": {"2017": 1}, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Statistical considerations for crowdsourced perceptual ratings of human speech productions", "year": 2019, "url": "https://www.tandfonline.com/doi/abs/10.1080/02664763.2018.1547692", "author": "Daniel Fern\u00e1ndez and Daphna Harel and Panos Ipeirotis and Tara McAllister", "journal": "Journal of Applied Statistics", "volume": "46", "number": "8", "pages": "1364-1384", "publisher": "Taylor & Francis", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Crowdsourcing has become a major tool for scholarly research since its introduction to the academic sphere in 2008. However, unlike in traditional laboratory settings, it is nearly impossible to control the conditions under which workers on crowdsourcing platforms complete tasks. In the study of communication disorders, crowdsourcing has provided a novel solution to the collection of perceptual ratings of human speech production. Such ratings allow researchers to gauge whether a treatment yields meaningful change in how human listeners' perceive disordered speech. This paper will explore some statistical considerations of crowdsourced data with specific focus on collecting perceptual ratings of human speech productions. Random effects models are applied to crowdsourced perceptual ratings collected in both a continuous and binary fashion. A simulation study is conducted to test the reliability of the \u2026</div></div></div>", "eprint": "http://e2953b6e947ea30a22403bfd.dnwkqcxbcr.maxcdn-edge.com/wp-content/uploads/2018/11/Statistical-considerations-for-crowdsourced-perceptual-ratings-of-human-speech-productions.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:eJjLl3UG7CkC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "WWW'18: Proceedings of the 2018 World Wide Web Conference", "year": 1970, "url": "https://hal.archives-ouvertes.fr/hal-01907226/", "author": "Pierre-Antoine Champin and Fabien Gandon and Lionel M\u00e9dini and Mounia Lalmas and Panagiotis Ipeirotis"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:S_Qw7xXuMuIC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Detecting Employee Misconduct and Malfeasance", "year": 1970, "url": "http://cgi.di.uoa.gr/~gvalk/pubs/detectica_misconduct.pdf", "author": "George Valkanas and Panos Ipeirotis and Foster Provost and Josh Attenberg and Jennifer Chin and Chathra Hendahewa and Abe Stanway and Bernando Suryanto and Bharath Vivekananda Swamy", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In the United States financial firms have the regulatory obligation to monitor the communications of their employees (eg, emails, chats, phone calls) in order to detect misconduct. Some forms of misconduct are illegal activities (eg, insider trading, bribery) while others are policy violations (eg, improper security practices, or inappropriate language use). Traditionally, firms have deployed relatively simple rule-based systems for employee surveillance. Such systems generate many false positive alerts and are hard to adapt to the changing environment. Recently, firms have attempted to improve their systems by transitioning from the rule-based techniques to statistical machine learning approaches. However, they still treat the problem of misconduct detection as a single-document classification problem. We present an approach that focuses on actors, connections among actors, and on cases of misconduct. Furthermore, we highlight the importance of having a \u201chuman-in-the-loop\u201d approach, where humans are both guided by and guide the system at the same time, in order to detect malfeasance faster and to adapt to changing environments. We also discuss how humans can play a key role for detecting shortcomings of existing machine-learningbased malfeasance-detection systems. Our multifaceted approach has been developed and tested in real environments within both massive and smaller financial institutions, and we discuss practical constraints and lessons learned. 1</div></div></div>", "eprint": "http://cgi.di.uoa.gr/~gvalk/pubs/detectica_misconduct.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:fc7zyzPI2QAC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "System, method and computer-accessible medium for trade surveillance", "year": 2015, "url": "https://patents.google.com/patent/US20150363879A1/en", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">An exemplary system, method and computer-accessible medium can be provided, which can include, for example, receiving digital data related to a suspicious trade (s), determining a first entity (s) associated with the suspicious trade (s) based on the digital data, and determining a relationship between the first entity (s) and a second entity based (s) on a proximity between the first entity (s) and the second entity (s). The proximity used to determine the relationship can be a logical proximity. The logical proximity can be determined based on a communication (s) between the first entity (s) and the second entity (s).</div></div></div>", "eprint": "https://patentimages.storage.googleapis.com/1f/6f/31/0ed90bc93a3718/US20150363879A1.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Gs1AF5H0x94C", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Modeling Dependency in Prediction Markets", "year": 2010, "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1718942", "author": "Nikolay Archak and Panagiotis G Ipeirotis", "publisher": "NYU Working Paper No. CEDER-10-05", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">In the last decade, prediction markets became popular forecasting toolsin areas ranging from election results to movie revenues and Oscarnominations. One of the features that make prediction marketsparticularly attractive for decision support applications is that theycan be used to answer what-if questions and estimate probabilities ofcomplex events. Traditional approach to answering such questionsinvolves running a combinatorial prediction market, what is not alwayspossible. In this paper, we present an alternative, statistical approachto pricing complex claims, which is based on analyzing co-movements ofprediction market prices for basis events. Experimental evaluation ofour technique on a collection of 51 InTrade contracts representing theDemocratic Party Nominee winning Electoral College Votes of a particularstate shows that the approach outperforms traditional forecastingmethods such as price and return regressions and can be used to extractmeaningful business intelligence from raw price data.</div></div></div>", "eprint": "https://archive.nyu.edu/bitstream/2451/29885/2/ConditionalPredictionMarkets.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:ldfaerwXgEUC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Message from the DBRank'10 program co-chairs", "year": 2010, "url": "https://www.researchwithnj.com/en/publications/message-from-the-dbrank10-program-co-chairs", "author": "Panagiotis G Ipeirotis and Amelie Marian", "journal": "Proceedings-International Conference on Data Engineering", "pages": "5452774", "publisher": "Institute of Electrical and Electronics Engineers Inc.", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\">Skip to main content \u2026 \n</div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:Vch7EZszQGgC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Improving product search with economic theory", "year": 2010, "author": "Beibei Li and PG Ipeirotis and A Ghose", "pages": "293-296", "publisher": "IEEE"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:lSLTfruPkqcC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Searching Digital Libraries", "year": 1970, "url": "https://link.springer.com/content/pdf/10.1007/978-0-387-39940-9_327.pdf", "author": "Panagiotis G Ipeirotis", "volume": "19", "pages": "2518-2521", "publisher": "Springer", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">The values in the relations of a relational database are elements of one or more underlying sets called domains. In practical applications, a domain may be infinite, eg, the set of natural numbers. In this case, the value of a relational calculus query when applied to such a database may be infinite, eg,{njn! 10}. A query Q is called finite if the value of Q when applied to any database is finite.</div><div class=\"gsh_csp\">Even when the database domains are finite, all that is normally known about them is that they are some finite superset of the values that occur in the database. In this case, the value of a relational calculus query may depend on such an unknown domain, eg,{xj 8yR (x, y)}. A query Q is called domain independent if the value of Q when applied to any database is the same for any two domains containing the database values or, equivalently, if the value of Q when applied to a database contains only values that occur in the database \u2026</div></div></div>", "eprint": "https://pdfs.semanticscholar.org/a3a4/d90ef27f200cc4c251df0e30c6154daff42c.pdf"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:u9iWguZQMMsC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Volatility of Informed Bets; or Why All Efficient and Accurate Prediction Markets are Identical", "year": 2008, "url": "http://scholar.google.com/scholar?cluster=15881459054276410228&hl=en&oi=scholarr", "author": "Nikolay Archak and Panagiotis G Ipeirotis", "publisher": "NYU Working Paper No. CEDER-08-07", "abstract": "<div class=\"gsc_vcd_value\" id=\"gsc_vcd_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">Nowadays, there is a significant experimental evidence of excellent ex-post predictive accuracy in certaintypes of prediction markets, such as markets for presidential elections. This evidence shows that predictionmarkets are efficient mechanisms for aggregating information and are more accurate in forecasting events thantraditional forecasting methods, such as polls. In this paper, we present a model of a prediction market with abinary payoff on a competitive event involving two parties where the underlying \u00e2\u00ac Sabilities\u00e2\u00ac? of the competingparties evolve as Ito diffusions. We show that if the prediction market for this event is efficient and accurate, the price of the corresponding contract will also follow a diffusion and its instantaneous volatility is a functionof only the current claim price and its time to expiration. We then generalize our results to competitive eventsinvolving more than two parties and show that \u2026</div></div></div>"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:NhqRSupF_l8C", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}, {"bib": {"title": "Stay Elsewhere? The Economic Impact of Location-based Hotel Features: A View from Remote Sensing Image Analysis", "year": 2008, "author": "Anindya Ghose and Panagiotis Ipeirotis and Beibei Li"}, "source": "citations", "id_citations": "PA9La6oAAAAJ:fPk4N6BV_jEC", "_filled": true, "cites_per_year": {}, "citedby": 0, "last_updated_ts": 1562675024, "last_updated": "2019-07-09 12:23:44"}]